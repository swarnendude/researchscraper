# Scraped Content

Total URLs: 24

---

## ✓ How to build a moat in the age of AI: workflow depth and proprietary data | Jessie Sheff posted on the topic | LinkedIn

**URL:** https://www.linkedin.com/posts/jessie-sheff-a67b6a37_building-a-moat-in-the-age-of-ai-activity-7396931743468965888-7eYE

Jessie Sheff

2mo

Edited

Report this post

In a new blog post, I (tried) to tackle the challenging question of how to build a moat in the age of AI. I outline two major categories where vertical AI companies can build real moats: workflow depth and proprietary data. Whether through core workflow systems with AI deeply embedded, forward-deployed engineering, custom integrations, or novel data capture, these are the edges that create compounding advantages.

And a shoutout to the Insight portfolio companies that were the inspiration for this post:

Inspiren

Filevine

MARKT-PILOT

Motorq

Klir

Litmus

, and many more shared here!

91

1 Comment

Like

Comment

Share

Copy

LinkedIn

Facebook

X

Heidi Ortman Sheff

2mo

Report this comment

Awesome!!

Like

Reply

1 Reaction

To view or add a comment,

sign in

---

## ✓ Exploring the Vertical-Domain Reasoning Capabilities of Large Language Models

**URL:** https://arxiv.org/html/2512.22443v1

Exploring the Vertical-Domain Reasoning Capabilities of Large Language Models

Jie Zhou, Xin Chen, Jie Zhang, Zhe Li

School of Computer Engineering, Jiangsu Ocean University

jzhou23@jou.edu.cn, lizhe@jou.edu.cn

Abstract

Large Language Models (LLMs) are reshaping learning paradigms, cognitive processes, and research methodologies across a wide range of domains. Integrating LLMs with professional fields and redefining the relationship between LLMs and domain-specific applications has become a critical challenge for promoting enterprise digital transformation and broader social development. To effectively integrate LLMs into the accounting domain, it is essential to understand their domain-specific reasoning capabilities. This study introduces the concept of vertical-domain accounting reasoning and establishes evaluation criteria by analyzing the training data characteristics of representative GLM-series models. These criteria provide a foundation for subsequent research on reasoning paradigms and offer benchmarks for improving accounting reasoning performance. Based on this framework, we evaluate several representative models, including GLM-6B, GLM-130B, GLM-4, and OpenAI GPT-4, on a set of accounting reasoning tasks. Experimental results show that different prompt engineering strategies lead to varying degrees of performance improvement across models, with GPT-4 achieving the strongest accounting reasoning capability. However, current LLMs still fall short of real-world application requirements. In particular, further optimization is needed for deployment in enterprise-level accounting scenarios to fully realize the potential value of LLMs in this domain.

Exploring the Vertical-Domain Reasoning Capabilities of Large Language Models

Jie Zhou, Xin Chen, Jie Zhang, Zhe Li

School of Computer Engineering, Jiangsu Ocean University

jzhou23@jou.edu.cn, lizhe@jou.edu.cn

1

Introduction

With the rapid development of artificial intelligence technologies, fields such as big data, supercomputing, brain-inspired intelligence, and large language models (Large Language Models, LLMs), particularly general-purpose natural language models, have attracted widespread attention from both academia and industry. Artificial intelligence has become a new engine for social intelligence and a core driving force for a new round of technological innovation and industrial transformation. It is also a key driver of national innovation capacity and an important strategic component of national security. In 2017, the State Council issued the New Generation Artificial Intelligence Development Plan, which identified artificial intelligence as a major strategic priority, emphasized the importance of strengthening China’s advantages in the AI field, and promoted interdisciplinary exploratory research. The plan encouraged the integration of artificial intelligence with mathematics, engineering, and other disciplines, strengthened foundational research, and supported the application of AI technologies across various sectors.

In July 2023, multiple national ministries jointly issued the Interim Measures for the Administration of Generative Artificial Intelligence Services, encouraging innovation and application of generative artificial intelligence technologies across industries and domains, and promoting the establishment of a standardized, orderly, and innovative governance framework. This policy context has created favorable conditions for the integration of LLMs with accounting practice.

As LLMs continue to evolve, they are no longer limited to foundational computing power or model-scale competition, but are increasingly driving the emergence of intelligent industries characterized by deep application integration. With the rapid deployment of general-purpose LLMs in vertical domains, how to effectively integrate LLMs into specific professional workflows and release their domain-specific potential has become a key direction for future research and technological development. Compared with narrowly specialized models, general-purpose LLMs demonstrate strong advantages in accounting-related tasks, including richer cross-domain knowledge, enhanced prompt understanding capabilities, and flexible reasoning and inference processes. These strengths enable LLMs to be applied across a wide range of accounting scenarios, such as intelligent financial analysis, tax compliance, auditing support, and management decision making. However, despite rapid exploration and experimentation, effective domain-specific LLMs for accounting have not yet been systematically established, and the practical effectiveness of LLM-based accounting systems remains limited.

In existing applications that integrate LLMs with accounting tasks, prompt engineering is commonly adopted as the primary interaction paradigm. This approach enhances model performance by constructing structured prompts or task-specific templates. However, such methods lack in-depth analysis of the 

[Content truncated...]

---

## ✓ How to Build a Lasting Vertical AI Moat | Alex de Bold posted on the topic | LinkedIn

**URL:** https://www.linkedin.com/posts/alexdebold_dude-wheres-my-moat-activity-7355777412393062400-0-ld

Alex de Bold

6mo

Report this post

This!

Lasting Vertical AI moats center around:

1. Data Gravity: Proprietary data assets competitors can't replicate.

2. Platform Lock-in: Building multi-product ecosystems that enhance stickiness.

3. Brand & Trust: Amplified by partnerships & industry word-of-mouth.

Nic Poulos

6mo

"Moats are dead."

"Speed is all that matters in the post-LLM era."

Let me share a perspective on why these claims are BS.

We can probably agree on a few things:

> The standalone virtues of early hyper-growth are undeniable.

> Some moats of the past are dead or dying (cf. CHGG, LZ, SSTK, FVRR).

> While the world would be a simpler place if defensibility was moot, it is in the interest of big capital allocators to claim that speed is now all that matters.

A+ execution has always been table stakes for winners... but it's never been a guarantee of success either. When the benefits of AI accrue to all great teams, we believe other sources of defensibility matter MORE, not less.

In our latest edition of Euclid Insights, we address what it truly takes to build durable defensibility in the age of AI.

You'll find:

a. A deep dive into why moats matter now more than ever.

b. Analysis on whether speed alone can sustain long-term advantage.

c. A clear framework for evaluating moat potential in Vertical AI startups.

Key insights from our research:

+ Vertical provides surface area for moats (public vSaaS show this lasting power with +30% more profitability & 6 years older vs. peers on average).

+ Companies that rely solely on rapid execution (and capital) still risk commoditization—just ask Siebel, Zenefits, Hopin or Lensa.

+ The importance of moats like usage + data loops are amplified by AI.

Lasting Vertical AI moats center around:

1. Data Gravity: Proprietary data assets competitors can't replicate.

2. Platform Lock-in: Building multi-product ecosystems that enhance stickiness.

3. Brand & Trust: Amplified by partnerships & industry word-of-mouth.

But in our view, two loom largest at inception:

+ Domain Expertise: Deep embedding in your industry, stakeholders & SOPs.

+ Velocity: Any way you cut it, early speed is still key (and yes, more so today).

While we can share proven tactics, the truth is that no two moats are the same. That's what makes them so powerful. As Buffett said: "No formula... tells you that the moat is 28ft wide and 16ft deep. [Academics] can compute standard deviations and betas, but they can’t understand moats."

Get our full breakdown of Vertical AI moats in our latest essay here:

https://lnkd.in/g3ijFtYC

2

1 Comment

Like

Comment

Share

Copy

LinkedIn

Facebook

X

Rajbir Bhattacharya

6mo

Report this comment

interesting

Like

Reply

1 Reaction

To view or add a comment,

sign in

---

## ✓ Agentic Systems: A Guide to Transforming Industries with Vertical AI Agents

**URL:** https://arxiv.org/html/2501.00881v1

Agentic Systems: A Guide to Transforming Industries with Vertical AI Agents

Fouad Bousetouane

1,2

1

The University of Chicago, USA

2

2ndsight.ai

bousetouane@uchicago.edu

Abstract

The evolution of agentic systems represents a significant milestone in artificial intelligence and modern software systems, driven by the demand for vertical intelligence tailored to diverse industries. These systems enhance business outcomes through adaptability, learning, and interaction with dynamic environments. At the forefront of this revolution are Large Language Model (LLM) agents, which serve as the cognitive backbone of these intelligent systems.

In response to the need for consistency and scalability, this work attempts to define a level of standardization for Vertical AI agent design patterns by identifying core building blocks and proposing a

Cognitive Skills

Module, which incorporates domain-specific, purpose-built inference capabilities. Building on these foundational concepts, this paper offers a comprehensive introduction to agentic systems, detailing their core components, operational patterns, and implementation strategies. It further explores practical use cases and examples across various industries, highlighting the transformative potential of LLM agents in driving industry-specific applications.

1

Introduction

The rapid evolution of technology has transformed business operations, with SaaS platforms

[

2

]

becoming essential for scalability and efficiency across industries. However, as industries face increasingly dynamic and complex environments, traditional SaaS solutions often fall short in meeting domain-specific and evolving needs.

To bridge this gap,

agentic systems

have emerged as a new generation of solutions. Powered by LLMs and advanced AI capabilities, they deliver intelligent, context-driven, and domain-specific solutions, addressing the limitations of both traditional SaaS platforms and context-aware systems.

1.1

The Shortcomings of Traditional SaaS Platforms

Traditional SaaS platforms serve as the backbone of business operations, offering reliable tools for managing workflows and maintaining operational consistency. Their architecture emphasizes horizontal scalability and general applicability, enabling businesses to standardize processes and optimize routine tasks across industries. This broad applicability makes SaaS ideal for managing repetitive tasks and scaling operations across diverse sectors. However, this generalized design often comes at the expense of domain-specific intelligence and flexibility, which are critical for addressing the unique challenges of dynamic and complex environments.

These limitations are evident in various industries:

•

E-commerce:

Platforms efficiently handle online transactions, product catalog management, and order tracking. Yet, they often require extensive customization to analyze customer purchasing behaviors, predict seasonal demand trends, or dynamically adjust inventory levels based on real-time sales data.

•

Multichannel Marketing:

Tools streamline campaign management across various channels, offering templates and automation for email, social media, and advertisements. However, their reliance on predefined workflows limits their ability to adapt quickly to shifting customer preferences, emerging trends, or competitor strategies.

•

Inventory Management:

Systems track stock levels and trigger reorders based on predefined thresholds. Despite this, they typically lack the ability to anticipate supply chain disruptions, respond to sudden demand spikes, or optimize procurement strategies using external market insights.

These examples underscore the reliance of traditional SaaS platforms on rule-based automation and structured data inputs. While effective for predictable and routine processes, they fall short in addressing domain-specific tasks that require contextual intelligence and adaptability.

1.2

The Transition to Context-Aware Systems

The limitations of traditional SaaS platforms have driven the adoption of

context-aware systems

, which aim to address these gaps by integrating real-time data and adaptability into workflows. By dynamically adjusting to evolving scenarios, these systems enable businesses to operate more effectively in increasingly complex environments. Context-aware systems are designed to:

•

Understand dynamic environments:

Incorporate real-time data to adjust workflows and outputs.

•

Bridge data to decisions:

Translate raw data into actionable insights without extensive manual intervention.

•

Adapt to evolving scenarios:

Adjust to unforeseen conditions or emerging trends.

While these systems represent a significant step forward, they still face challenges. For example:

•

Supply Chain Management:

Traditional tools track inventory but fail to predict disruptions caused by external factors such as weather events or geopolitical risks.

•

Healthcare:

Scheduling systems can manage appoi

[Content truncated...]

---

## ✓ Don't bother building a moat - Indie Hackers

**URL:** https://www.indiehackers.com/post/dont-bother-building-a-moat-3788693d4a

It seems like folks are always dropping platitudes about the importance of building a moat. But what does that actually mean for indie hackers?

Big companies have moats for days. Deep ones with water and crocodiles and drawbridges. Is that even a possibility for us? I can say that I’ve (unintentionally) created some (very) small moats in my day, but water and crocs are hard to come by.

I looked into what other indie hackers are doing and here's the short answer:

Yes we can. But maybe we shouldn't.

Types of moats

There are a lot of moats out there. Some apply to indie hackers. Some don't. We can break these loosely into business moats and personal moats.

Personal moats

This type of moat applies to indie hackers in a big way. I'd argue that it's the most important for us.

Think about it, what founders have name recognition among their customers? The top .0000001% of founders — Jobs, Musk, Bezos, etc. — and then us. I can't name the founder of any business in the middle ground. So unless you’re competing with Apple, you’ve got the advantage. You’re an expert. And you’re accessible.

So you should be a big part of your business's brand. Build in public. Emails should come from you. You should tweet from your personal account, not your business's. Put a "built by" in the footer of your website. You get the idea — just generally make sure your name and face are familiar to anyone who comes into contact with your product. And likewise, make sure anyone who comes into contact with you will get to know your product.

@jamesskylor

: Well the newest type of moat and monopoly is a personal moat. A personal monopoly. A personal monopoly is the unique intersection of your skills, knowledge, personality, and experiences that nobody else can compete with. It’s like a personal brand with a following - people who listen to you.

Business moats

While I think personal moats are the best thing for most of us to invest our time into, there are plenty of others. Let's start with the ones that indie hackers can leverage.

Moats that are worth a shot for indie hackers

Content:

We all know companies with this type of moat. Think Hubspot. Having a ton of content that hits the top of the SERP is a solid approach… but it's tough for most indie hackers to get there.

Communities

: Another great way to do it, and it's accessible to indie hackers. But note that this is time-intensive.

Tech:

You're probably not going to have a tech moat in the way that Apple has a tech moat. But you can build tech that is advanced enough to create a small moat. And the earlier/faster you build it, the harder it'll be for competitors to catch up.

Brand:

This includes the personal moat — indie hackers build these moats best by building in public IMO. But either way, this is a nice and accessible one, assuming you can get traction.

Distribution:

When most companies talk about a distribution moat, it's about how many people they're reaching. For indie hackers, it should be about who they're reaching — niche down and build a moat of distribution within that niche.

Network effects:

This is when every new user adds value to your product — think Tinder. If you get traction and you happen to have a product that can leverage these effects, then this is a solid moat. Unfortunately, you may run into that famous chicken/egg situation where your products need users to be valuable but your product needs to be valuable to get users.

@csallen

: For indie hackers, the easiest moat is often network effects. Make it so every additional customer improves the quality of your product for other customers. Communities are a simple way to do this.

Customer relationships and loyalty:

Do right by your customers. Indie hackers have an advantage here. Make that personal connection and get them invested in your product.

I think that last one is really worth emphasizing. Tech moats, content moats, distribution moats… they're all pretty tough to do. But creating relationships just requires being available, proactive, and kind. Like I said above, indie hackers have an advantage when they get close and personal with customers because, generally speaking, founders don't do that. So focus on that relationship. The more invested your customers are in you and your business, the less likely they are to churn, and the more likely they are to recommend you. Relationships are a great moat that anyone can create quite easily.

A quick note on content moats. If you're going to go HAM on it and make it happen, consider a hub-and-spoke model where you link from a central hub of more general content to increasingly specific content. This is great for SEO and really helpful for your readers. Glossaries are an option too.

@IamRafiqul

: If you're in an industry that deals with many technical and complex terms, then consider building glossary pages. Even better is to create an individual glossary page for each term and make it informative for the users. Next, try to find an angle

[Content truncated...]

---

## ✓ Old Moats for New Models: Openness, Control, and Competition in Generative AI | NBER

**URL:** https://www.nber.org/papers/w32474

Old Moats for New Models: Openness, Control, and Competition in Generative AI

Pierre Azoulay

,

Joshua L. Krieger

&

Abhishek Nagaraj

Share

X

LinkedIn

Facebook

Bluesky

Threads

Email

Link

Working Paper

32474

DOI

10.3386/w32474

Issue Date

May 2024

Revision Date

July 2024

Drawing insights from the field of innovation economics, we discuss the likely competitive environment shaping generative AI advances. Central to our analysis are the concepts of appropriability—whether firms in the industry are able to control the knowledge generated by their innovations—and complementary assets—whether effective entry requires access to specialized infrastructure and capabilities to which incumbent firms can ration access. While the rapid improvements in AI foundation models promise transformative impacts across broad sectors of the economy, we argue that tight control over complementary assets will likely result in a concentrated market structure, as in past episodes of technological upheaval. We suggest the likely paths through which incumbent firms may restrict entry, confining newcomers to subordinate roles and stifling broad sectoral innovation. We conclude with speculations regarding how this oligopolistic future might be averted. Policy interventions aimed at fractionalizing or facilitating shared access to complementary assets might help preserve competition and incentives for extending the generative AI frontier. Ironically, the best hopes for a vibrant open source AI ecosystem might rest on the presence of a “rogue” technology giant, who might choose openness and engagement with smaller firms as a strategic weapon wielded against other incumbents.

Acknowledgements and Disclosures

We thank Josh Lerner, Janet Freilich, Shane Greenstein, Joshua Gans, Shikhar Ghosh, Pam Mishkin, Roland Szabo, Nikhil Naik, Rishi Bommasani, Juan Mateos-Garcia, Yoon Kim, and Roger Levy for useful discussions. Nilo Mitra and Yanqi Cheng provided able research assistance. We acknowledge the help of GPT-4 and Claude 3 Sonnet as unparalleled brainstorming partners, expert paraphrasers, and whisperers of imaginary references. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.

Citation and Citation Data

Copy Citation

Pierre Azoulay, Joshua L. Krieger, and Abhishek Nagaraj, "Old Moats for New Models: Openness, Control, and Competition in Generative AI," NBER Working Paper 32474 (2024), https://doi.org/10.3386/w32474.

Copy to Clipboard

Download Citation

MARC

RIS

BibTeΧ

Download Citation Data

Other Versions

May 15, 2024

Published Versions

Old Moats for New Models: Openness, Control, and Competition in Generative Artificial Intelligence

, Pierre Azoulay, Joshua Krieger, Abhishek Nagaraj. in

Entrepreneurship and Innovation Policy and the Economy, volume 4

, Jones and Lerner. 2025

Related

Topics

Industrial Organization

Market Structure and Firm Performance

Industry Studies

Development and Growth

Innovation and R&D

Programs

Productivity, Innovation, and Entrepreneurship

Working Groups

Innovation Policy

Conferences

NBER Entrepreneurship and Innovation Policy and the Economy Conference, 2024

More from the NBER

In addition to

working papers

, the NBER disseminates affiliates’ latest findings through a range of free periodicals — the

NBER Reporter

, the

NBER Digest

, the

Bulletin on Health

, and the

Bulletin on Entrepreneurship

— as well as online

conference reports

,

video lectures

, and

interviews

.

2025, 17th Annual Feldstein Lecture, N. Gregory Mankiw," The Fiscal Future"

Feldstein Lecture

Presenter:

N. Gregory Mankiw

N. Gregory Mankiw, Robert M. Beren Professor of Economics at Harvard University, presented the 2025 Martin Feldstein...

2025, Methods Lecture, Raj Chetty and Kosuke Imai, "Uncovering Causal Mechanisms: Mediation Analysis and Surrogate Indices"

Methods Lectures

Presenters:

Raj Chetty

&

Kosuke Imai

SlidesBackground materials on mediationImai, Kosuke, Dustin Tingley, and Teppei Yamamoto. (2013). “Experimental Designs...

2025, International Trade and Macroeconomics, "Panel on The Future of the Global Economy"

Panel Discussion

Presenters:

Oleg Itskhoki

,

Paul R. Krugman

&

Linda Tesar

Supported by the Alfred P. Sloan Foundation grant #G-2023-19633, the Lynde and Harry Bradley Foundation grant #20251294...

---

## ✗ https://medium.com/%40sanguit/how-to-win-at-vertical-ai-43952d95df7b

**URL:** https://medium.com/%40sanguit/how-to-win-at-vertical-ai-43952d95df7b

Error scraping: 403 Client Error: Forbidden for url: https://medium.com/%40sanguit/how-to-win-at-vertical-ai-43952d95df7b

---

## ✓ The Last-Mile Moat: Why Vertical AI Gets Valued in Billions

**URL:** https://www.linkedin.com/pulse/last-mile-moat-why-vertical-ai-gets-valued-billions-aditya-singh-t6wdc

If you look at the venture capital heat map right now, the signal is undeniable. While the foundational model wars rage on between OpenAI, Google, and Anthropic, the smart money has quietly moved up the stack.

The biggest venture bets are now flowing to companies that chose one industry, one workflow, one ugly problem—and went offensively deep.

The valuations are staggering—and these are just a few examples. Healthcare startup Abridge

raised $300M at $5.3B valuation

. Harvey has reached an

$8 billion valuation

serving legal professionals, and

Tempus sits at $7 billion

in healthcare oncology—underscoring how quickly vertical AI leaders can compound value once they own a workflow.

Which creates this deceptively simple question for founders and investors:

if these companies are using the same OpenAI and Anthropic APIs as everyone else, why are they worth billions while generic AI wrapper companies struggle to survive?

The Context Window Fallacy

To understand why Vertical AI wins, one must first understand where horizontal AI hits a wall. General LLMs are stateless inference engines—brilliant, yes… but fundamentally amnesiac.

When a procurement officer needs to analyze a supply chain risk, they do not just need a dictionary definition of "risk". They need to know their specific vendor history, the clauses in their Master Services Agreements, which routes have been delayed three quarters in a row, and what geopolitical volatility does to their shipping lanes.

A general model possesses none of this context.

Now layer in the economics.

Training frontier models is so capital-intensive that only a handful of labs can do it at scale.

Stanford’s AI Index

estimates compute-only training costs at around $78 million for GPT-4 and $191 million for Gemini Ultra.

Which creates a weird inversion: the more expensive the models get to build, the more widely they get rented.

This is where the vertical AI playbook quietly demolishes the horizontal approach—by solving the

last mile of intelligence.

And that “last mile” isn’t a small implementation detail. It’s an architectural gap—one generalist model, on its own, is structurally incapable of closing.

The Data Moat: From RLHF to DPO

The second differentiator for vertical giants is the data feedback loop. General models are trained on the "average" of the internet and fine-tuned via Reinforcement Learning from Human Feedback (RLHF) to be helpful and harmless.

Vertical AI startups, however, fine-tune models using Domain-Specific Preference Optimization (DPO).

Consider a radiology AI startup. They do not merely use an off-the-shelf vision model; they aggregate feedback from thousands of radiologists. Every time a doctor accepts or rejects the AI's diagnosis, that action becomes a high-fidelity training signal. Over time, the model drifts away from the "general mean" and becomes hyper-specialized.

Recommended by LinkedIn

AI's Lemming Rush: How to Spot the Cliff Before You…

Charles Williams

3 months ago

The AI Startup Taxonomy: The 5 Types Every Founder and…

Yaron Orenstein

3 weeks ago

Chinese startup DeepSeek shakes up AI world, puts US…

Press Insider

1 year ago

This creates a "Data Flywheel":

Day 1:

The product is useful because it wraps a good API with a good UI.

Day 100:

The product is defensible because it has ingested terabytes of private client data that no competitor can access.

Day 1000:

The product is unassailable because the model is fine-tuned on edge cases that simply do not exist in the public training data of OpenAI or Google.

Consider Tempus in oncology. They did not train their own LLM; they built the largest comprehensive clinical and molecular oncology dataset in the world. Their AI engine operates within the context of 1+ million digitized pathology slides, genomic sequences, and treatment histories spanning 45 countries.

No matter how good the next OpenAI model is, it will not have access to that proprietary data.

Moving from Chatbots to Agentic Workflows

The final reason these companies are valued so highly is that they are killing the "Chat" interface.

Professionals do not want to chat with a bot; a freight operator does not want to discuss a bill of lading—they want it generated, validated, and filed.

Vertical AI is rapidly shifting toward

Agentic Workflows

.

We are seeing systems that operate autonomously:

The Trigger:

A new email arrives with a purchase order.

The Agent:

The AI parses the attachment, checks inventory in the ERP, validates pricing against the contract in the CLM, and drafts a confirmation.

The Review:

The human only steps in to approve the final action  .

This marks the transition from SaaS (Software as a Service) to

Service-as-a-Software

. You are no longer selling a tool to help a lawyer work faster; you are selling a system that does the first 80% of the legal work.

The Economics of Defensibility

This architectural shift explains the funding bifurcation in 2025, where vertical A

[Content truncated...]

---

## ✓ AI Moats - by Gennaro Cuofano - The Business Engineer

**URL:** https://businessengineer.ai/p/ai-moats

AI Moats

Gennaro Cuofano

Oct 10, 2024

30

7

Share

I analyzed the AI landscape in late 2022, and came up with a framework to understand how to build competitive moats in the new AI paradigm. The below is my full perspective on that, updated based on current developments!

As soon as I saw ChatGPT at the end of November 2022, I deeply considered

​ the nature of competition (as it developed) in the AI industry.​

The Business Engineer  is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.

Subscribe

I wrote the below in early December 2022, and I think it gets confirmed more and more each day as the AI industry develops.

I’ve added a few more points and paragraphs based on current developments, but today's main question remains.

Indeed, the main question that kept popping up in my head was:

If we all build tools on top of ChatGPT/OpenAI or a few similar models, how can we build competitive moats?

In other words, how can we build a company on top of AI with a long-term advantage that cannot be easily commoditized?

And just like two years back, my answer is the same, and it can be summarized as you can absolutely build AI Moats even if you’re not operating at the foundational layer!

I think there are a few things to take into account here.

As we went along this intense journey, where nearly two years have seemed a decade, what I’ll explain below has actually been confirmed.

We saw the emergence of startups like Perplexity AI - outside pure foundational players like OpenAI, who will need to spend billions on infrastructure alone - becoming precious companies.

In reality, as I’ll explain below, valuable companies will emerge in each layer of the AI industry, but each layer will have a completely different logic.

Let me explain!

​

In the three layers of AI theory in the AI Business Models book, I explained in detail what the AI business ecosystem looks like.

​

There, I explained how, on the software side, the industry is developing according to three layers:

Foundational Layer

: General-purpose engines like GPT-3, with features such as being multi-modal, driven by natural language, and adapting in real-time.

Middle Layer

: Comprised of specialized vertical engines replicating corporate functions and building differentiation on data moats.

App Layer

: Rise of specialized applications built on top of the middle layer, focusing on scaling up user base and utilizing feedback loops to create network effects.

Now, once you've understood that, let's see what - I argue - can create a competitive moat in AI.

If you need more clarity on it, jump here and read it all!

This is part of a whole new Business Ecosystem.

In short:

Software: we moved from narrow and constrained to general and open-ended (the most powerful analogy at the consumer level is from search to conversational interfaces).

Hardware:

we moved from CPUs to GPUs, powering up the current ​AI revolution.

Business/Consumer: we're moving from a software industry that is getting 10x better as we speak just by simply integrating OpenAI's API endpoints to any existing software application.

Code is getting way cheaper, and barriers to entering the already competitive software industry are getting much, much lower. At the consumer level, first millions, and now hundreds of millions of consumers across the world are getting used to a different way to consume content online, which can be summarized as the move from indexed/static/non-personalized content to generative/dynamic/hyper-personalized experiences.

Remixing foundational models (GPT, Claude, Meta AI, DALL-E, Stable Diffusion, Midjourney, and so forth)

While there are still some arbitrage opportunities, those are quickly shrinking!

Legacy/foundational models (the general-purpose engines like GPT-4, Anthropic, Stable Diffusion, and so forth) are getting better and better at handling multiple modalities, at the point of becoming multimodal!

If you're building an AI-based product, you can use this multimodality to add impressive features at 1/100 the cost and effort...

So, for instance, if you're building an AI product, you can re-mix these models, too.

One example of this “agnosticism” is Perplexity AI, which, in the backend of its product, has multiple LLMs, which are shuffled based on what serves the best answers.

While also providing users with a choice of model to pick.

The interesting take here—as foundational players fiercely compete for a piece of the API massive cake—is that they are all slashing the prices of their APIs, thus making it extremely cheap for any startup to build a new AI tool, as long as you can create a compelling UX!

This window of opportunity might exist for the next five years as the API market consolidates around a few players, enjoying winner—take—all—effects!

Of course, chances are that this market might become an oligopoly, where a few players control most of it and thus capt

[Content truncated...]

---

## ✓ Vertical AI Explained: The Next Generation of Tech Titans | NEA

**URL:** https://www.nea.com/blog/tomorrows-titans-vertical-ai

Blog

Tomorrow’s Titans: Vertical AI

by Tiffany Luck and James Kaplan

The past two years have marked a rapid evolution in AI and the core building blocks of modern software. The zeitgeist moment of ChatGPT set off a chain reaction of innovation, competition and R&D investment in AI, and two years later, we see unprecedented growth of new horizontal applications, such as ChatGPT, Perplexity, Claude, Midjourney, Cursor, ElevenLabs, and more. As AI capabilities mature to offer generative, agentic and multi-modal functions, we see an exciting opportunity for new verticalized applications.

The next titans of software will be vertical AI companies in specialized industries.

In this post we share our framework for vertical AI, exploring why we believe now is the optimal time to build industry-specific AI solutions and the key considerations for creating category winners.

Services to Software Turning Point

In the

cloud era

, we witnessed large vertical software winners such as Procore ($11B), Toast ($21B), and ServiceTitan ($9B). [1] The winners of this first wave followed a common pattern:

System of record: Automate and centralize customer data

Payments & billing: Streamline financial workflows and business intelligence

Marketplace: Bring ecosystem of industry participants onto one platform

Now generative and agentic AI unlocks another potential layer:

Agentic system: AI actions that can significantly automate remaining labor-heavy workflows. As the marginal cost of machine intelligence continues to decline due to intense competition among foundation model providers and hundreds of billions of capex investment in GPU infrastructure, it’s easier than ever to build a large business that makes AI useful for specialized, industry-specific work. [2]

The nature of software is changing from a system of record to a system of actions. [3] In the AI era, defensibility is likely to emerge from specialization and orchestration of AI agents, lending itself to verticalized solutions. Early examples include Harvey AI and Abridge.

With AI agents advancing beyond mere digitization to actively performing tasks on behalf of end users, software companies have the opportunity to capture significantly more total addressable market (TAM). By tapping into the

$11T

U.S. labor spend [4] — far exceeding the approximately

$450B

enterprise software market [5] — these companies can unlock unprecedented growth.

In this post, we discuss:

Why now is the right time to build in vertical AI

Where vertical AI can win over horizontal products

The new vertical AI playbook

Four questions worth debating

Ideas for industries where vertical AI is likely to emerge

The New Control Point: Agents

Today, software is designed for user initiated workflows. The largest software companies—such as Salesforce, Workday, Oracle, and SAP—function as systems of record, relying heavily on human-entered data. Consider the average sales representative, who

spends six hours a week

[

6] updating their CRM (we feel for them!). The competitive advantage of these systems of record is rooted in three key factors:

High switching costs due to their role in storing and structuring critical data

Ownership of workflows because users operate within their platforms

A robust ecosystem of applications and integrations that creates lock-in

However, in a world where software takes actions on behalf of users, the traditional workflow advantage of systems of record diminishes. If AI agents process data before it ever reaches these systems (and generate new data abstracted from the systems of record), the incumbents risk losing their advantage tied to data ownership and the resulting switching costs.

The "control point"—the most mission-critical software in a customer’s stack that drives upselling opportunities—has often traditionally been the system of record. For instance, in home services, it’s Dispatch and CRM; in education, it’s the LMS and SIS.

In the future, the control point may shift to the agentic layer, potentially reducing the importance of existing systems of record and redefining the competitive landscape.

Perfect storm of opportunity for vertical AI

While agentic AI capabilities are still in their infancy, we think there’s a confluence of factors that makes it the right time right now to build a vertical AI disruptor.

Getting the job done:

Early signals of agents achieving higher performance in discrete jobs or specialized workflows while generalist agents struggle with consistency

Potential to capture larger ACVs:

If vertical agents can augment human labor, they can also command higher ACVs and scale revenue faster than traditional SaaS tools.

Labor shortages in mission-critical trades:

Productive agents are the antidote to labor shortages in the U.S.

Today

, ~38% of Americans have a four-year college degree, compared to 30% 10 years ago and 23% 20 years ago. [7] Education in trades and vocational upskilling lags behind. America has

[Content truncated...]

---

## ✓ Indistinguishable from Magic: The 7 Sources of Moat in AI | Blackbird

**URL:** https://blackbird.vc/blog/indistinguishable-from-magic-part-3

Get Investment

About

About Blackbird

Team

Careers

Foundation

Investment

Get Investment

Portfolio

For Investors

Community

Stories

Startup Jobs

Programs

Sunrise Festival

Contact Us

Contact Form

Artist In Rotation

Recent Articles

Investment

Investment Notes: Ivo Series B

We’re proud to lead the US$55M Series B round into Ivo, alongside Costanoa Ventures, Uncork Capital, Fika Ventures, GD1 and Icehouse Venture

Investment

Investment Notes: Gilmour Space Series E

From Series A to unicorn: continuing our journey with Gilmour Space

Investment

2025 Year in Review

Today we're reflecting on the year that was at Blackbird.

Investment

Investment Notes: Elyos

Indistinguishable from Magic: The 7 Sources of Moat in AI

Date Published:

December 19, 2023

‍

“In business, I look for economic castles protected by unbreachable moats” - Warren Buffet

‍

Welcome to Part 3 of a 4-part series on the state of AI and our emerging perspectives.

In

Part 1

we took stock of the past year and the speed and scale of the developing AI market. In

Part 2

we walked through the AI market map and highlighted pockets of opportunity. Now, in Part 3 we share insights into what we look for in AI companies and our mental model for how we think about AI companies building sustainable competitive advantage, or moat.

‍

Part 3: The 7 Sources of Moat in AI

‍

Cautionary tales of “GPT Wrappers”

‍

There are oodles of blogs, articles and thought pieces on the need for “defensibility”, “sustainable advantage” or “competitive moat” in AI (

example

,

example

,

example

,

example

).

And there are cautionary tales of “GPT Wrappers”, products with a thin surface layer built on top of third party model APIs, which lack enough unique product depth and IP to protect against fast-copies.

An often referenced case study is

Jasper AI

. Jasper

took off early

and aggressively, shooting from basically nothing to U$42M ARR in its first year and ~U$72M in its second. Around that time, in October 2022, it raised an impressive U$125M Series A round at a $1.5B valuation.

‍

Jasper’s initial growth was underscored by being a first mover and the fact it got early access to GPT-3 at a time when the API was closed to the broader market.

But then it stumbled.

In November 2022, one month following the Series A raise announcement, OpenAI released GPT-3.5 along with its free ChatGPT user application. ChatGPT grew rapidly gaining 100M MAUs in 2 months, the fastest acquisition of users of any tech product in history, and it could fulfil many of the use cases that Jasper served, for free.

In the same month, OpenAI switched its API to be openly accessible which resulted in many fast-followers to the generative copy opportunity (

Copy.ai

,

Grammarly

,

Quillbot

,

Copysmith

,

Notion AI,

Clickup AI

,

Hypotenuse

,

Writesonice

,

Wordtune

,

Rytr

).

Jasper had a great product but a fairly thin layer of moat. It was using an off-the-shelf LLM that was delivering a significant proportion of product value for its primary use cases, marketing copy, without much room for fine-tuning, the rest of the product e.g. user workflows and editing features, had not yet been fully fleshed out.

To its credit, Jasper is well capitalised, has built a large community, seems to be investing heavily in product and LLM capabilities, and still has a shot at success… but the point remains, moat is important.

‍

7 Sources of Moat

‍

The risk of the “GPT Wrapper” naturally gives rise to the question of what is moat and how do you build it?

Many say “

it’s about owning the data

”. In reality, there are multiple levers for building moat and the one you should pull on depends on your product strategy and use case.

In our experience to date, there are seven core sources of moat in AI, let’s explore each of these.

‍

Moat 1 - The Product Layer

‍

Recent advancements in AI have led to a resurgence in vertical and horizontal SaaS solutions. Historically, these solutions have focused on workflows, with powerful AI just an API away. They now can play a big role in automation too, increasing their value propositions, ACVs (Average Contract Values) and TAMs (Total Addressable Markets).

AI has a different role to play depending on the product and vertical. Customer support products (e.g.

Intercom

,

Zendesk

) are being easily disrupted given the opportunity for AI to enable the core user need i.e. effective, chat-based resolution of user support tickets. Products in other verticals like manufacturing and construction may find this disruption is less pronounced.

A helpful question to ask is

“how much of the product’s value proposition is or can be derived from AI-based features?”

. The answer might be 50%+ (the product is AI-dominant), 25-50% (the product is AI-core), 10-25% (the product is AI-enabled) or ~5-10% (the product is AI-assisted).

‍

The greater the role of AI in the product (i.e. AI-dominant or -core), the more important it is to

[Content truncated...]

---

## ✗ https://www.producthunt.com/categories/ai-agents

**URL:** https://www.producthunt.com/categories/ai-agents

Error scraping: 403 Client Error: Forbidden for url: https://www.producthunt.com/categories/ai-agents

---

## ✗ https://openai.com/enterprise-privacy/

**URL:** https://openai.com/enterprise-privacy/

Error scraping: 403 Client Error: Forbidden for url: https://openai.com/enterprise-privacy/

---

## ✓ The 7 Most Powerful Moats For AI Startups - YouTube

**URL:** https://www.youtube.com/watch?v=bxBzsSsqQAM&

About

Press

Copyright

Contact us

Creator

Advertise

Developers

Terms

Privacy

Policy & Safety

How YouTube works

Test new features

© 2026 Google LLC

---

## ✓ AI Moats: Why Vertical Integration Matters | Eze Vidra posted on the topic | LinkedIn

**URL:** https://www.linkedin.com/posts/ezevidra_theres-a-lot-of-talk-about-moats-or-lack-thereof-activity-7389347972993527809-pCTJ

Eze Vidra

Eze Vidra is an Influencer

3mo

Report this post

There's a lot of talk about moats (or lack-thereof) in AI.

As

Greylock Partners

'

Jerry Chen

argues in 'The New New Moats',  AI doesn't change how startups market, sell or partner.

But unless you're building a foundational model (which most startups are not), it's hard to create moats in AI. The real moat in AI is vertical integration. That means not only building an agent that does the job it's supposed to do, but rather embedding the solution in a way that is almost seamless for the client's workflow.

My latest post looks a bit deeper at this topic. On AI moats, vertical integration and building defensibility in application layer startups. Link in the first comment.

11

1 Comment

Like

Comment

Share

Copy

LinkedIn

Facebook

X

Eze Vidra

3mo

Report this comment

Why vertical integration is the only defensibility in AI

https://www.vccafe.com/2025/10/29/why-vertical-integration-is-the-only-true-defensibility-in-ai

/

Like

Reply

1 Reaction

To view or add a comment,

sign in

---

## ✗ https://medium.com/included-vc/the-next-trillion-dollar-opportunity-why-vertical-ai-is-the-future-of-saas-b7119614cee5

**URL:** https://medium.com/included-vc/the-next-trillion-dollar-opportunity-why-vertical-ai-is-the-future-of-saas-b7119614cee5

Error scraping: 403 Client Error: Forbidden for url: https://medium.com/included-vc/the-next-trillion-dollar-opportunity-why-vertical-ai-is-the-future-of-saas-b7119614cee5

---

## ✓ Why AI Moats Still Matter (And How They've Changed) - YouTube

**URL:** https://youtu.be/fgzr3PhzIMk?si=MOIvp4efukHvHjqX

About

Press

Copyright

Contact us

Creator

Advertise

Developers

Terms

Privacy

Policy & Safety

How YouTube works

Test new features

© 2026 Google LLC

---

## ✓ Unique AI | Agentic Solutions for Financial Services

**URL:** http://unique.ai

Enterprise AI for Finance

The secure AI platform that gives you the flexibility to build and buy.

Book a Demo

Your browser does not support the video tag.

Adopt Completely. Integrate Selectively. Extend Endlessly.

Choose the complete platform or integrate modular components into your existing infrastructure.

Accelerate internal AI development

Enhance existing AI capabilities

Leverage IT investments

Learn More

Introducing Unique AI

A solution built for both users and developers for the precision, governance, and performance financial institutions demand.

Secure Ecosystem

Financial Agents

AI Workspace

Core Architecture

Secure Ecosystem

Our MCP Hub provides a secure control plane that connects your enterprise systems to any AI model, enabling seamless integrations through MCP Connectors, while enforcing strong governance and protection across all AI workflows.

Learn More

Secure Ecosystem

Financial Agents

AI Workspace

Core Architecture

Financial Agents

Our AI Agents provide focused capabilities such as KYC and investment analysis. They run in our interface or directly in your systems as stand-alone components, enabling fast, compliant automation and decision support.

AI Factory

Secure Ecosystem

Financial Agents

AI Workspace

Core Architecture

AI Workspace

A secure workspace that integrates collaborative chat, knowledge base management, and custom agent creation. Enhance this environment with powerful Add-Ons for seamless translation services and dynamic agentic tables.

Learn More

Secure Ecosystem

Financial Agents

AI Workspace

Core Architecture

Core Architecture

Our AI Engine orchestrates research agents, secure RAG pipelines, and benchmarking with strong identity governance, providing the backbone and toolkit for building, evaluating, and scaling enterprise-grade AI.

Learn More

Built for Finance. Tested by Finance.

We co-develop workflows and agents with our clients to meet industry-specific needs and regulations for maximum impact.

Wealth Management

Hedge Funds

Retail Banking

Insurance

Private Equity

Unique AI for Wealth Management

Unique AI for Hedge Funds

Unique AI for Retail Banking

Unique AI for Insurance

Unique AI for Private Equity

Trusted by Finance

Our Clients

to the case study

"The platform does in minutes what previously took employees hours to do,” –

Steve Blanchet

, Head of Group Technology Strategy and Innovation

92%

Firm-wide adoption rate

1,5-2h

Time saving employee/week

to the case study

to the case study

"We chose to partner with Unique for their combination of technological and industry expertise, their international client community, and their commitment to enterprise-grade security. Our joint efforts are setting the stage for more personalized, proactive client service.” –

Mariam Rassai

, Chief Digital and Data Officer

to the case study

Learn More

"Collaborating with Unique accelerated our go-to-market with multiple practical applications, thanks to their unique platform approach. We also benefited from the collaborative spirit of Unique's partner network, which has evolved into a thriving ecosystem of like-minded organizations working together to unlock the potential of generative AI.” –

Matthias Plattner,

Head Channels & Digital Services

Learn More

Pictet

BNPP

Julius Bär

Drive Firm-Wide Adoption with Ease

At Unique AI, we support our clients every step of the way on their AI journey: from implementation to adoption.

Unique AI Transformers

Embedded experts who work with your business and IT teams to implement real use cases quickly.

Unique AI Academy

Training and upskilling programs that teach your teams how to use,  build and scale with Unique AI.

Learn More

Security Without Compromise

Modern data practices, encryption, and independent audits keep your operations compliant and protected.

Trust Center

FAQ

How quickly can Unique AI be implemented in my organization?

Estimated timeframe: 1-5 months.

This is a rough estimate and can vary significantly based on the complexity of your setup requirements, the readiness of your data, and the resources you have available for the project. For a more precise timeline, a detailed assessment by the implementation team would be necessary.

What are the set-up options?

Unique offers four different deployment options, depending on client needs:

Multi-tenant:

In its Azure cloud in Switzerland.

Single tenant on Unique Cloud:

Unique offers clients the option to have all their data stored in their own physical Azure Tenant. The client can choose the location, whether it is in Switzerland, the EU, or any other country where Microsoft services are available.

Customer-managed Tenant:

Unique can also be installed in the customer tenant, where hosting is done on Azure servers in the client’s environment.

On-premise:

The client can store and process data on their own servers.

Each setting comes with specific responsibilities for both Unique and the client, as well as 

[Content truncated...]

---

## ✗ https://www.sciencedirect.com/science/article/abs/pii/S0048733322000415

**URL:** https://www.sciencedirect.com/science/article/abs/pii/S0048733322000415

Error scraping: 403 Client Error: Forbidden for url: https://www.sciencedirect.com/science/article/abs/pii/S0048733322000415

---

## ✗ https://www.tandfonline.com/doi/full/10.1080/15265161.2023.2250293

**URL:** https://www.tandfonline.com/doi/full/10.1080/15265161.2023.2250293

Error scraping: 403 Client Error: Forbidden for url: https://www.tandfonline.com/doi/full/10.1080/15265161.2023.2250293

---

## ✓ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/startups/comments/1ilkg43/ai_will_obsolete_most_young_vertical_saas/

Go to startups

r/startups

•

Few_Incident4781

简体中文

繁體中文

Français

Čeština

Español (Latinoamérica)

Türkçe

Español (España)

Deutsch

Nederlands

Norsk (Bokmål)

Bahasa Melayu

AI will obsolete most young vertical SAAS startups, I will not promote

This is an unpopular opinion, but living in New York City and working with a ton of vertical SaaS startups, meaning basically database wrapper startups that engineer workflows for specific industries and specific users, what they built was at one point in time kind of innovative, or their edge was the fact that they built these like very specific workflows. And so a lot of venture capital and seed funding has gone into these types of startups. But with AI, those database wrapper startups are basically obsolete. I personally feel like all of these companies are going to have to shift like quickly to AI or watch all of their edge and what value they bring to the table absolutely evaporate. It's something that I feel like it's not currently being priced in and no one really knows how to price, but it's going to be really interesting to watch as more software becomes generated and workflows get generated.

I’m not saying these companies are worth nothing, but their products need to be completely redone

EDIT: for people not understanding:

The UX is completely different from traditional vertical saas. Also in real world scenarios, AI does not call the same APIs as the front end. The data handling and validation is different. It’s 50% rebuild. Then add in the technical debt, the fact that they might need a different tech stack to build agents correctly, different experience in their engineers.

the power struggles that occur inside companies that need a huge change like this could tank the whole thing alone.

It can be done, but these companies are vulnerable. The edge they have is working with existing customers to get it right. But they basically blew millions on a tech implementation that’s not as relevant going forwards.

Investors maybe better served putting money into a fresh cap table

Read more

Share

---

## ✓ AI Moats Are Not What You Think — VC Office Hours 1 - YouTube

**URL:** https://www.youtube.com/watch?v=5EByvOZVPXI&

About

Press

Copyright

Contact us

Creator

Advertise

Developers

Terms

Privacy

Policy & Safety

How YouTube works

Test new features

© 2026 Google LLC

---

## ✓ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/SaaS/

How a B2B company makes millions with their tiny Youtube channel

u/illeatmyletter

•

How a B2B company makes millions with their tiny Youtube channel

B2B SaaS

I came across this breakdown and it completely flipped how I thought about YouTube. Figured it might be valuable for you as well.

Most founders assume YouTube only works if you go big. Massive subscriber counts, viral videos, influencer-level reach. But this case study proves that's wrong, well at least for B2B.

There's a small company in immigration + tax optimization. Nothing sexy. Their average client pays around $2,000 though. Their YouTube channel has maybe 1,000 to 1,500 subscribers. And from that channel alone, they've booked 500+ sales calls. That's easily seven figures in revenue from what most people would call a "dead" channel.

But it gets crazier… They get only around 350 to 400 views per day. About 30 videos total. But they close roughly half their calls. They even spun up a second channel in another language with under 30 subscribers, and it already brought in multiple paying clients.

This is why B2B YouTube is a completely different game.

Subscriber count is a vanity metric. What actually matters:

Who's watching: are they decision-makers or random browsers?

Why they're watching: are they actively looking for a solution?

How much one customer is worth: if a client pays $2k, $10k, or more, you don't need scale

The videos that drive revenue on this channel aren't flashy. They're boring, high-intent, search-driven stuff: "how to get residency in X," "best tax residency for digital nomads," country comparisons etc. These aren't entertainment videos. They're decision-stage videos, which means the viewer is already problem-aware and actively searching for a solution. That's why they convert.

If you're selling something where one customer is worth a few thousand dollars or more, obsessing over subscriber count makes no sense. A small channel with the right topics can outperform a larger audience watching for entertainment. The leverage comes from intent, not scale.

I’d love to hear form other founders to see if you’ve had similar results? Have any of you tried YouTube as an acquisition channel? What results did you see?

---

## ✓ The Empty Promise of Data Moats | Andreessen Horowitz

**URL:** https://a16z.com/the-empty-promise-of-data-moats/

The Empty Promise of Data Moats

Martin Casado

and

Peter Lauten

share

Copy Link

Email

X

LinkedIn

Facebook

Hacker News

WhatsApp

Flipboard

Reddit

Posted May 9, 2019

Data has long been lauded as a competitive

moat

for companies, and that narrative’s been further hyped with the recent wave of AI startups. Network effects have been similarly

promoted

as a defensible force in building software businesses. So of course, we constantly hear about the combination of the two: “data network effects” (heck, we’ve talked

about them

at length ourselves).

But for enterprise startups — which is where we focus — we now wonder if there’s practical evidence of data network effects at all. Moreover, we suspect that even the more straightforward data

scale

effect has limited value as a defensive strategy for many companies. This isn’t just an academic question: It has important implications for where founders invest their time and resources. If you’re a startup that assumes the data you’re collecting equals a durable moat, then you might underinvest in the other areas that actually

do

increase the defensibility of your business long term (verticalization, go-to-market dominance, post-sales account control, the winning brand, etc).

Treating data as a magical moat can misdirect founders from focusing on what’s really needed to win

In other words, treating data as a magical moat can misdirect founders from focusing on what is really needed to win. So, do data network effects exist? How might a scale effect behave differently from the traditional network effect? And once we get past the hype of having to have them… how can startups establish more

durable

data moats — or at least figure out where data best plays into their strategy?

Data + network effects ≠ data network effects

Broadly defined, a “network” is at play when a system of users/customers/endpoints/etc. are structurally arranged in a network. In our context, such networks are often built around a technology, product, or service supporting the network structure, whether constructed around engagement features (e.g., social networks) and/or protocols (e.g., Ethernet, email, cryptocurrencies).

Network

effects

occur when

the value of participating in a network goes up for the participants as more nodes come on to the network, or as engagement increases between existing nodes. Imagine trying to have a one-way phone conversation or call only five people in the world and no one else; the telephone system became more valuable as more users joined the network. Other common, more modern examples of network effects may include social networks, online marketplaces, and cryptonetworks.

Systems with network effects generally have the property of

direct

interactions between the nodes over a defined interface or protocol. Joining the network requires conforming to some standard, which increases direct interaction for all nodes and makes those interactions increasingly stickier. But when it comes to the popular narrative around

data

network effects, we don’t often see the same sticky, direct interaction play out (let alone mechanical interdependencies between nodes due to protocols or interfaces).

There generally isn’t an inherent network effect that comes from merely having more data.

The Cold Start Problem

Andrew Chen's forthcoming book examines the impact of network effects on some of the world's largest companies.

Pre-Order the Book

Most data network effects are really scale effects

Most discussions around data defensibility actually boil down to scale effects, a dynamic that fits a looser definition of network effects in which there is no direct interaction between nodes. For instance, the Netflix recommendation engine can predict that you’re likely to enjoy show

Y

if most of the viewers of your favorite film

X

also tend to watch show

Y

, even though those users don’t directly interact with each other. More data means better recommendations, which means more customers, and even more data… the famous “flywheel”.

Yet even with scale effects, our observation is that data is rarely a strong enough moat. Unlike traditional economies of scale, where the economics of fixed, upfront investment can get increasingly favorable with scale over time, the exact

opposite

dynamic often plays out with data scale effects: The cost of adding unique data to your corpus may actually go up, while the value of incremental data goes down!

Take the case of a company using a chat bot to respond to customer support inquiries. As you can see from the graph below, creating an initial corpus from customer support transcripts is likely to provide answers to simple inquiries (“Where is my package?”). But the vast majority of inquiries are far messier, many of which are only ever asked once (“Where is that thing that I’ve been waiting to arrive on my front door step?”). So in this limiting case, collecting useful inquiries becomes more difficult over time. And, a

[Content truncated...]

---

