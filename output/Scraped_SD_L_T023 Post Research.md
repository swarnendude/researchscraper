# Scraped Content

Total URLs: 31

---

## ✓ Workday Study Looks at How Much Time Is Spent Fixing AI Errors - Business Insider

**URL:** https://www.businessinsider.com/workday-study-looks-at-time-spent-fixing-ai-errors-2026-1?utm_source=chatgpt.com

Business Insider tells the innovative stories you want to know

---

## ✗ https://www.seo.com/blog/ai-slop/

**URL:** https://www.seo.com/blog/ai-slop/

Error scraping: 403 Client Error: Forbidden for url: https://www.seo.com/blog/ai-slop/

---

## ✓ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/NoStupidQuestions/comments/1q02dlv/when_will_ai_content_stop_being_slop/?utm_source=chatgpt.com

Go to NoStupidQuestions

r/NoStupidQuestions

•

[deleted]

When will AI content stop being slop?

Sorry, this post was deleted by the person who originally posted it.

Share

---

## ✓ How AI ruined Quora - by Jonn Elledge

**URL:** https://open.substack.com/pub/jonn/p/how-ai-ruined-quora?utm_campaign=post-expanded-share&utm_medium=web

How AI ruined Quora

Fully automated luxury mansplaining.

Jonn Elledge

May 11, 2024

13

Share

This was sent to paying subscribers

back in January

.

I have, in my time, thrown a lot of questions at the internet. Why is there a Napoleon I and Napoleon III, but no Napoleon II.

1

Why is Europe considered a continent when it is very clearly just a peninsula of Asia.

2

Sometimes the answers to these questions end up in this newsletter as content; sometimes they end up coming out of my mouth in social situations, surprising and delighting my friends.

At some point – I’m not sure when – such questions led me to sign up to Quora, “a platform to ask questions and connect with people who contribute unique insights and quality answers”, which, annoyingly, you need to log into to read. I don’t remember what question led me there, let alone the quality of the answer, but I’m assuming – given both my interests, and the sort of thing it’s been spamming me with ever since – it was somewhere in the intersection of history, national identity and international relations. At any rate, for several years now, the site has been emailing me other examples of the sorts of questions the algorithm thinks I might be interested in. The fact it sends them to my backup email account, the one I use for group chats and other stuff I don’t want littering my main inbox, suggests that I saw this one coming.

For a long time, the sort of questions Quora would fire back at me, along with the first few words of the top ranked answer, made a pretty good fist of being Elledge-specific clickbait. “Why is England considered a country while the UK or Britain, which it is part of, is also a country?” “Why can’t we dig deeper than 12.2 km into the Earth?” “Did Henry VIII regret executing Thomas More?” And once upon a time, I’m told, the platform was actually rather good: a place filled with scientists and historians, where you might actually find an actual expert to answer your question.

In recent years, though, it’s gone noticeably downhill. The people most active on the platform today will show their bonafides not through their qualifications or professional status, but by listing the countries they’ve visited and the languages they speak. There’s something car-crash compelling about the

tone

of the site, too. In a manner familiar from food writers and also, I fear, this newsletter, answers to big questions will inevitably begin with half-remembered personal anecdotes, possibly dating back to the late 1970s. Quora taps into the urge many people feel, when exposed to an internet connection, to show off. It’s found a way to monetise mansplaining.

These days, it sometimes struggles to hit even those intellectual heights, and in recent months I’ve noticed the questions I’m emailed growing increasingly, mindbogglingly weird. “Why is King Charles not called ‘King Charles the Ninth’?” (Well, why would he be?) “Why is Paris not the capital of France?” (Did I miss a memo?) “Why do Brits call their currency ‘quid’? What’s wrong with calling it ‘pounds’ like everyone else does?” (Oooh, that was so close to being an excellent question.)

The site doesn’t make it easy to identify who is asking its questions – to find out, you have to go from the email, to the website, to the page for the specific question, to the button marked details, which is probably more clicking than I’m going to do for anything that isn’t a video of two mismatched animals who’ve somehow become best friends – and the internet is full of people demonstrating quite outstanding levels of stupidity so I never thought much of any of this.

Until, that is, I spotted an answer beginning with the phrase, “IDIOT QUORA PROMPT GENERATOR AGAIN!” Because it turns out, if you go to the bother of clicking from email, to website, to question, to details, a lot of these questions aren’t being asked by real people at all. They’re being asked by an AI.

Not all of them, to be clear: the ones apparently aimed at winding up specific groups (Americans, Europeans, and so on) are almost certainly being asked by other specific groups (Europeans, Americans, etc). But where the questions become almost gleefully absurd (”What are people wearing in heaven?”; “Which K-pop idol has a crush on you?”; “What can we say to our cats?”) they almost certainly didn’t come from a human being at all.

The reason this is happening, the tech writer Kate Bevan told me, when I called her to ask, essentially, WTF, is almost certainly because “artificial intelligence” is a deeply misleading name.

“The category error everyone makes,” she explained, “is to treat AI as a knowledge engine. It’s not: it’s spicy autocomplete.” AI based on machine learning such as the large language models (LLMs) that power Chat GPT,  or the Quora Prompt Generator, are very good at pattern matching: predicting the next word in a sentence in a generally compelling manner. But, while that’s one aspect of intelligence, it’s far from the only one. T

[Content truncated...]

---

## ✓ AI Slop: Avoiding Low-Quality AI Content | Copy.ai

**URL:** https://www.copy.ai/blog/ai-slop?utm_source=chatgpt.com

Content Creation

February 10, 2025

June 27, 2025

AI Slop: Avoiding Low-Quality AI Content

CONTENTS

H2 Heading link

H3 Heading link

Nathan Thompson

Nathan is a revenue-focused marketing leader. By day he manages Content right here at Copy.ai, by night he enjoys family time in the Rocky Mountains!



A new term has emerged in AI-generated content: AI slop. As businesses increasingly rely on Artificial Intelligence tools to create content at scale, a growing concern arises—the proliferation of low-quality, generic, or even nonsensical output. This so-called "AI slop" not only weakens content marketing efforts but also erodes audience trust and engagement.

In this guide, we’ll dive deep into the concept of AI slop, exploring its origins, impact, and strategies to avoid it. You'll learn how to recognize AI slop, understand its negative effects on your content strategy, and implement best practices to ensure high-quality, engaging AI-generated content.

By the end of this article, you'll have the knowledge and tools necessary to navigate AI content creation with confidence. You’ll see how platforms like Copy.ai can help you harness AI’s power while maintaining the quality and authenticity your audience expects.

Free tools

to get started quickly and easily.

So, let’s begin this journey together and uncover the pitfalls of AI-generated slop—and, more importantly, how to avoid them.

‍

What is AI Slop?

AI slop refers to low-quality, often nonsensical content generated by AI tools when they lack proper guidance or human oversight. It results from over-reliance on automation without essential quality control measures in place.

The term "AI slop" originates from the early days of AI-generated content when businesses rushed to use AI tools for scaling content production. Many prioritized quantity over quality, leading to a flood of generic, poorly structured, and sometimes incoherent content that failed to engage audiences or achieve marketing goals.

Understanding AI slop is crucial for anyone involved in social media content creation or digital marketing today. With AI technology evolving rapidly, it’s easier than ever to generate content for platforms like TikTok quickly at scale. However, without real life human oversight, this content can quickly degrade into AI-generated slop.

The rise of AI slop carries significant implications for businesses investing in content marketing. Poor-quality content damages brand reputation, erodes audience trust, and ultimately fails to generate leads or engagement. This is especially true since it is now so easy to create deepfakes and AI-generated images. Consumers are increasingly discerning, making AI slop a serious liability.

To avoid the AI slop trap, businesses must approach AI-generated content strategically. This means investing in tools and platforms that prioritize quality over quantity, such as Copy.ai's GTM AI platform or OpenAI’s ChatGPT. By combining oversight from human beings with new AI technology like AI chatbots, Large Language Models (LLMS), generative AI, and image generators, entrepreneurs and businesses can leverage the efficiency of automation while ensuring their content remains high-quality and engaging.

As we explore AI slop further, we’ll examine its impact on content marketing and outline strategies for avoiding it.

Impact of AI Slop

The negative effects of AI slop on content quality and audience engagement cannot be overstated. When businesses rely too heavily on automated content generation without proper oversight, the result is a flood of low-quality, generic content that fails to resonate with readers.

Loss of Audience Trust

AI slop significantly erodes audience trust. When readers encounter content that is poorly written, lacks coherence, or feels irrelevant, they quickly lose confidence in the brand behind it. This loss of trust leads to decreased engagement, lower site traffic, and ultimately, lost sales and revenue.

Negative SEO Consequences

Another major consequence of AI slop is its impact on search engine rankings. As search algorithms become more sophisticated at identifying and penalizing low-quality content, businesses that produce AI slop risk having their content buried in search results—or removed from search indexes altogether. This can severely impact organic traffic and lead generation efforts.

For example, one company saw its search rankings plummet after publishing a high volume of AI-generated content without proper review and editing. Search engines flagged their content as low-quality, causing a significant drop in organic traffic and leads. It took months of effort to clean up their content and regain their rankings.

The Business Case for Quality AI Content

Avoiding AI slop is essential for maintaining credibility and effectiveness in content marketing. Businesses that prioritize quality over quantity and incorporate human oversight into AI-driven workflows can produce content that truly resonates wi

[Content truncated...]

---

## ✓ More than 90% companies have seen their AI investments failing and blame for this should go to ..., says study - The Times of India

**URL:** https://timesofindia.indiatimes.com/technology/tech-news/more-than-90-companies-have-seen-their-ai-investments-failing-and-blame-for-this-should-go-to-says-study/articleshow/124241294.cms?utm_source=chatgpt.com

Edition

IN

IN

US

English

English

à¤¹à¤¿à¤¨à¥à¤¦à¥

à¤®à¤°à¤¾à¤ à¥

à²à²¨à³à²¨à²¡

à®¤à®®à®¿à®´à¯

à¦¬à¦¾à¦à¦²à¦¾

à´®à´²à´¯à´¾à´³à´

à°¤à±à°²à±à°à±

àªà«àªàª°àª¾àª¤à«

Weather

Sign In

TOI

Today's ePaper

News

Technology News

Tech News

More than 90% companies have seen their AI investments failing and blame for this should go to ..., says study

Trending

NYT Connections Hints

Wordle Today Clues

NYT Strands

Google Memo To H 1B Visa Holders

Anupam Mittal

Optus Outage

H 1 B Visa Fee Hike

Goldman Sachs

Sridhar Vembu

Ben Stiller

NYT Connections Hints

Wordle Today Clues

NYT Strands

Google Memo To H 1B Visa Holders

Anupam Mittal

Optus Outage

H 1 B Visa Fee Hike

Goldman Sachs

Sridhar Vembu

Ben Stiller

NYT Connections Hints

Wordle Today Clues

NYT Strands

Google Memo To H 1B Visa Holders

Anupam Mittal

Optus Outage

H 1 B Visa Fee Hike

Goldman Sachs

Sridhar Vembu

Ben Stiller

More than 90% companies have seen their AI investments failing and blame for this should go to ..., says study

TOI Tech Desk

/ TIMESOFINDIA.COM /

Updated: Oct 01, 2025, 07:35 IST

Share

AA

+

Text Size

Small

Medium

Large

New research identifies "workslop," poor quality AI-generated content, as the reason 95% of corporate AI investments yield no returns. This deceptive output, lacking substance, burdens employees with corrections. A survey found 40% of US workers recently received workslop. Experts advise leaders to implement clear guidelines for intentional AI use, ensuring meaningful contributions and preventing increased workload.

A new study has tried to reason the biggest complaint that majority of companies have with their AI investment -- that they give zero return. A recent MIT study had put the figure of AI investment failures at 95%.

Now a study from researchers at consulting company BetterUp Labs, in collaboration with Stanford Social Media Lab, has reasoned the AI failure with a new term -- "workslop". The study coins the new term to describe low-quality, AI-generated work: âWorkslop.â

Published in the Harvard Business Review, the research highlights how Workslop may explain why 95% of organizations experimenting with AI report no return on investment.

Workslop, defined as âAI-generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task,â is often unhelpful, incomplete, or missing critical context. The researchers warn that it shifts the burden downstream, forcing others to interpret, correct, or redo the work.

The researchers also conducted an ongoing survey of 1,150 full-time, U.S.-based employees, with 40% of respondents saying theyâd received Workslop in the past month.

To combat Workslop, researchers urge workplace leaders to model intentional AI use and establish clear guidelines for acceptable practices. âLeaders must set guardrails around norms to ensure AI contributes meaningfully,â the study advises.The findings highlight the need for thoughtful integration of AI tools to avoid creating more work rather than less.

MIT study says 95% of Gen-AI pilots at companies are failing

A recent MIT study indicates that 95% of organizations studied get zero return on their AI investment. The study said that 95% of organizations found zero return despite enterprise investment of $30 billion to $40 billion into GenAI. MIT researchers are said to have studied 300 public AI initiatives to try and suss out the "no hype reality" of AI's impact on business.

About the Author

TOI Tech Desk

The TOI Tech Desk is a dedicated team of journalists committed to delivering the latest and most relevant news from the world of technology to readers of The Times of India. TOI Tech Deskâs news coverage spans a wide spectrum across gadget launches, gadget reviews, trends, in-depth analysis, exclusive reports and breaking stories that impact technology and the digital universe. Be it how-tos or the latest happenings in AI, cybersecurity, personal gadgets, platforms like WhatsApp, Instagram, Facebook and more; TOI Tech Desk brings the news with accuracy and authenticity.

Read More

End of Article

Follow Us On Social Media

Visual Stories

Previous

From Neeru Bajwa to Shehnaaz Gill: Leading ladies shaping Punjabi cinemaâs bright future

Entertainment

In pics: Vijay Sethupathiâs fierce avatar in Bigg Boss Tamil 9 promo

tv

10 small dog breeds perfect for apartment living: Family-friendly and easy to care for

Lifestyle

Disha Parmar approved top 10 stylish looks

tv

Navratri 2025: Shraddha Kapoor, Alia Bhatt, and other divas' inspired pink ethnic looks for day 9

Entertainment

From Chic to Classy: Priyanka Mohanâs style evolution

Entertainment

Mamitha Baiju mesmerizes; nature meets grace

Entertainment

Monalisa stuns in red saree for Durga Puja

tv

Best family games that will make your kids forget all about screens

Lifestyle

Karthika Nair shines bright captivating hearts with beauty and poise

Entertain

[Content truncated...]

---

## ✓ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/planhub/comments/1q4r4ju/ai_slop_is_killing_user_engagement_with_pinterest/?utm_source=chatgpt.com

Go to planhub

r/planhub

•

Planhub-ca

"AI Slop" is killing user engagement, with Pinterest as the prime victim

A recent report highlights that "AI slop", low-quality, mass-produced content, is driving users away from social platforms, with Pinterest being the first major casualty. Users are reportedly "exhausted" by the flood of nonsensical, AI-generated images that clutter search results, making the platform's core promise of human curation and inspiration nearly impossible to fulfill. The phenomenon has become so pervasive that "slop" was named Merriam-Webster's Word of the Year for 2025. This digital pollution isn't just an annoyance; it's an existential threat to platforms that rely on visual authenticity, as algorithms struggle to distinguish between genuine creativity and machine-made garbage.

"AI Slop" refers to low-quality, mass-produced digital content used to farm engagement.

Pinterest users are leaving because AI clutter makes finding real inspiration impossible.

"Slop" was officially named the Word of the Year for 2025 by Merriam-Webster.

Over 50% of new articles online are now estimated to be AI-generated.

Major brands like Coca-Cola and McDonald's faced backlash for using "slop" in ads.

Primary Source (French)

Numerama

Context

on "Slop"

Read more

Share

---

## ✗ https://medium.com/@sdavis_70997/your-ai-content-is-killing-reader-trust-the-solution-humans-84dcf0c9df0c

**URL:** https://medium.com/@sdavis_70997/your-ai-content-is-killing-reader-trust-the-solution-humans-84dcf0c9df0c

Error scraping: 403 Client Error: Forbidden for url: https://medium.com/@sdavis_70997/your-ai-content-is-killing-reader-trust-the-solution-humans-84dcf0c9df0c

---

## ✗ https://www.forbes.com/sites/quickerbettertech/2025/09/17/hallucinations-inaccuracies-misinformation-how-tech-companies-are-killing-ais-credibility/?utm_source=chatgpt.com

**URL:** https://www.forbes.com/sites/quickerbettertech/2025/09/17/hallucinations-inaccuracies-misinformation-how-tech-companies-are-killing-ais-credibility/?utm_source=chatgpt.com

Error scraping: 403 Client Error: Forbidden for url: https://www.forbes.com/sites/quickerbettertech/2025/09/17/hallucinations-inaccuracies-misinformation-how-tech-companies-are-killing-ais-credibility/?utm_source=chatgpt.com

---

## ✓ Microsoft is Very Upset (About AI Slop - And Its Hilarious) - YouTube

**URL:** https://www.youtube.com/watch?v=hzM-lCT1CWI

About

Press

Copyright

Contact us

Creator

Advertise

Developers

Terms

Privacy

Policy & Safety

How YouTube works

Test new features

© 2026 Google LLC

---

## ✓ [2512.08273] AgentEval: Generative Agents as Reliable Proxies for Human Evaluation of AI-Generated Content

**URL:** https://arxiv.org/abs/2512.08273?utm_source=chatgpt.com

Computer Science > Artificial Intelligence

arXiv:2512.08273

(cs)

[Submitted on 9 Dec 2025]

Title:

AgentEval: Generative Agents as Reliable Proxies for Human Evaluation of AI-Generated Content

Authors:

Thanh Vu

,

Richi Nayak

,

Thiru Balasubramaniam

View a PDF of the paper titled AgentEval: Generative Agents as Reliable Proxies for Human Evaluation of AI-Generated Content, by Thanh Vu and 2 other authors

View PDF

HTML (experimental)

Abstract:

Modern businesses are increasingly challenged by the time and expense required to generate and assess high-quality content. Human writers face time constraints, and extrinsic evaluations can be costly. While Large Language Models (LLMs) offer potential in content creation, concerns about the quality of AI-generated content persist. Traditional evaluation methods, like human surveys, further add operational costs, highlighting the need for efficient, automated solutions. This research introduces Generative Agents as a means to tackle these challenges. These agents can rapidly and cost-effectively evaluate AI-generated content, simulating human judgment by rating aspects such as coherence, interestingness, clarity, fairness, and relevance. By incorporating these agents, businesses can streamline content generation and ensure consistent, high-quality output while minimizing reliance on costly human evaluations. The study provides critical insights into enhancing LLMs for producing business-aligned, high-quality content, offering significant advancements in automated content generation and evaluation.

Comments:

10 pages, 5 figures

Subjects:

Artificial Intelligence (cs.AI)

Cite as:

arXiv:2512.08273

[cs.AI]

(or

arXiv:2512.08273v1

[cs.AI]

for this version)

https://doi.org/10.48550/arXiv.2512.08273

Focus to learn more

arXiv-issued DOI via DataCite

Submission history

From: Thanh Vu [

view email

]

[v1]

Tue, 9 Dec 2025 06:03:25 UTC (447 KB)

Full-text links:

Access Paper:

View a PDF of the paper titled AgentEval: Generative Agents as Reliable Proxies for Human Evaluation of AI-Generated Content, by Thanh Vu and 2 other authors

View PDF

HTML (experimental)

TeX Source

view license

Current browse context:

cs.AI

< prev

|

next >

new

|

recent

|

2025-12

Change to browse by:

cs

References & Citations

NASA ADS

Google Scholar

Semantic Scholar

export BibTeX citation

Loading...

BibTeX formatted citation

×

loading...

Data provided by:

Bookmark

Bibliographic Tools

Bibliographic and Citation Tools

Bibliographic Explorer Toggle

Bibliographic Explorer

(

What is the Explorer?

)

Connected Papers Toggle

Connected Papers

(

What is Connected Papers?

)

Litmaps Toggle

Litmaps

(

What is Litmaps?

)

scite.ai Toggle

scite Smart Citations

(

What are Smart Citations?

)

Code, Data, Media

Code, Data and Media Associated with this Article

alphaXiv Toggle

alphaXiv

(

What is alphaXiv?

)

Links to Code Toggle

CatalyzeX Code Finder for Papers

(

What is CatalyzeX?

)

DagsHub Toggle

DagsHub

(

What is DagsHub?

)

GotitPub Toggle

Gotit.pub

(

What is GotitPub?

)

Huggingface Toggle

Hugging Face

(

What is Huggingface?

)

Links to Code Toggle

Papers with Code

(

What is Papers with Code?

)

ScienceCast Toggle

ScienceCast

(

What is ScienceCast?

)

Demos

Demos

Replicate Toggle

Replicate

(

What is Replicate?

)

Spaces Toggle

Hugging Face Spaces

(

What is Spaces?

)

Spaces Toggle

TXYZ.AI

(

What is TXYZ.AI?

)

Related Papers

Recommenders and Search Tools

Link to Influence Flower

Influence Flower

(

What are Influence Flowers?

)

Core recommender toggle

CORE Recommender

(

What is CORE?

)

Author

Venue

Institution

Topic

About arXivLabs

arXivLabs: experimental projects with community collaborators

arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.

Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.

Have an idea for a project that will add value for arXiv's community?

Learn more about arXivLabs

.

Which authors of this paper are endorsers?

|

Disable MathJax

(

What is MathJax?

)

---

## ✓ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/youtube/comments/1pmcl2f/youtube_needs_a_filter_for_ai_generated_content/?utm_source=chatgpt.com

Go to youtube

r/youtube

•

Chikadee_e

हिन्दी

Português (Brasil)

Français

Español (Latinoamérica)

Čeština

Italiano

Youtube needs a filter for "AI" generated content. Too much generated slop.

Hey. Especially last half year, Youtube has influx of "AI" generated slop. Not possible to discover new videos created by humans. And I'm starting to lose interest in discovering new videos/shorts. 1-2 year more and hand made videos will be drowned in generated slop and eventually, peoples will stop creating.

Youtube

really needs

a filter for "AI" generated content in settings or disable monetization for generated videos.

BTW: One stock video site added a robotic watermark to all previews of generated videos. It's also a great solution. It's visible, and you don't need to read the description. It would also be a good idea to tighten the rules for videos that aren't marked as synthetic by the channel author. It seems Youtube is allowing viewers to be deceived because it doesn't take action against those who pass off slop as real.

Read more

Share

---

## ✓ What is AI workslop? Research on costs and solutions

**URL:** https://www.betterup.com/blog/hidden-costs-workslop

Blog

>

Business

>

The hidden cost of AI “workslop” — and how leaders can fix it

The hidden cost of AI “workslop” — and how leaders can fix it

By

Elizabeth Perry, ACC

X

Elizabeth Perry is a Coach Community Manager at BetterUp. She uses strategic engagement strategies to cultivate a learning community across a global network of Coaches through in-person and virtual experiences, technology-enabled platforms, and strategic coaching industry partnerships.

With over 3 years of coaching experience and a certification in transformative leadership and life coaching from Sofia University, Elizabeth leverages transpersonal psychology expertise to help coaches and clients gain awareness of their behavioral and thought patterns, discover their purpose and passions, and elevate their potential. She is a lifelong student of psychology, personal growth, and human potential as well as an ICF-certified ACC transpersonal life and leadership Coach.

X

This article was reviewed by a subject matter expert to guarantee accuracy and depth. Content is reviewed and updated as needed to ensure it remains current and comprehensive.

September 29, 2025

- 6 MIN READ

Jump to section

AI is transforming the workplace at breakneck speed. But alongside the real productivity gains, a new phenomenon is quietly taxing organizations:

workslop

.

Workslop is AI-generated content that looks polished and complete — but is actually unhelpful, low-quality, or off the mark. It can take the shape of emails, documents, slide decks, or even code. While it may look good on the surface, workslop is often bloated, confusing, or just plain wrong. And according to new research from BetterUp and the Stanford Social Media Lab, workslop is far from rare.

How common is workslop?

Our September 2025 survey of 1,004 full-time U.S. desk workers revealed that:

40% of employees

believe they’ve received workslop in the last month.

On average, workers estimate that

15.4% of the work they receive

is AI workslop.

Managers are more exposed:

54% report receiving workslop

, compared with 38.5% of individual contributors.

More than half (53%) admit that at least some of the work they themselves send may be workslop.

In other words, workslop is circulating in every direction — sideways between peers (40%), up the chain to managers (19%), and down from leaders to their teams (16%).

The hidden tax of AI misuse

Workslop isn’t just annoying — it’s expensive.

Employees reported spending an average of

1 hour and 51 minutes

dealing with each instance of workslop, about 20 minutes longer than if the sender had done the work themselves. When translated into real costs, that wasted effort equates to an

“invisible tax” of $186 per month per employee

.

For an organization of 10,000 workers, that adds up to

over $9 million in lost productivity every year

.

More than wasted time: damaged trust and relationships

The toll of workslop isn’t just financial. It reshapes how colleagues see each other.

When employees receive workslop, they describe feeling:

Annoyed (54%)

Frustrated (46%)

Confused (38%)

Even

offended (22%)

And the reputational damage is real. About half of employees who received workslop said they viewed the sender as

less creative, capable, and reliable

. Forty-two percent saw them as less trustworthy, and over a third viewed them as less intelligent. Nearly one in three employees said they’d be

less likely to want to work with that person again

.

What leaders can do to reduce workslop

AI isn’t going away, but workslop doesn’t have to be part of the deal. Leaders can take proactive steps to set the tone:

Set clear AI guidelines.

Employees need direction on when and how AI should be used. Align AI use with your organization’s values, strategy, and vision.

Build adaptive mindsets.

BetterUp Labs’ research shows that workers with high optimism and high agency, a.k.a. the “Pilot mindset,” use AI more intentionally, to enhance

creativity

rather than just to shortcut work.

Recommit to collaboration.

Effective prompting, giving feedback, and sharing context are human skills that matter more than ever. Encourage teams to treat AI not as a crutch, but as a partner and to stay mindful of the impact their AI use has on colleagues.

Workslop spreads when AI work loses context and accountability.

Our research shows that leaders can curb it by setting clear guardrails, modeling thoughtful AI use, and cultivating

“pilot” mindsets

that use AI to enhance collaboration rather than avoid work.

BetterUp’s Human Transformation Platform

turns AI investments into real performance gains - embedding development into daily workflows, scaling the mindsets and skills that fuel sustained growth.

Moving beyond workslop

AI’s promise is real, but so are its pitfalls. By naming and addressing workslop, organizations can reclaim wasted time, rebuild trust, and unlock AI’s true potential as a tool for creativity and growth.

The Human Transformation 

[Content truncated...]

---

## ✓ What the Rise of AI Slop Means for Marketers

**URL:** https://www.meltwater.com/en/blog/ai-slop-consumer-sentiment-social-listening-analysis

What the Rise of AI Slop Means for Marketers

Ann-Derrick Gaillot and Anna Amarotti

Nov 27, 2025

7 min. read

Home

›

Blog

›

Social Listening

›

What the Rise of AI Slop Means for Marketers

View All

Social Listening

Social Listening Guide

Share Article

Request a demo

Usage of the term “AI slop” increased 9x in 2025 (from January 1 to November 20) compared to the same time period in 2024. This blog uses Meltwater’s social listening solution to track the rise of the term over time and dig into how audiences feel about low-effort, AI-generated content.

In 2025, as we’ve witnessed the rise of generative AI, we’ve also seen a flood of its unfortunate byproduct: a new category of low-quality content commonly referred to as “AI slop.” We first explored consumer attitudes toward

AI-generated content

at the beginning of this year. Since then, consumers have become increasingly discerning about the aesthetics of content from leading LLMs and generative AI tools. The

em-dash

has become synonymous with ChatGPT-produced text, while

gibberish text

is a telltale sign of AI-generated images. Through it all, “AI slop” has emerged as a catch-all term for genAI outputs that leave something to be desired

For marketers, the discussion around AI slop is an important one, highlighting how consumer preferences change with the rise of new technologies. We used our

social listening and analytics solution

to dig into the rise of the term, as well as what it reveals about audience preferences.

Learn more about how brands can build trust and prioritize excellence in the genAI age with our new report co-produced with The Webby Awards.

AI slop: What it is and where it came from

“AI slop” refers to low-quality, obviously AI-generated images, videos, and other content. The phrase has become mainstream as genAI content has proliferated across social platforms like Facebook and Pinterest. As the

New York Times pointed out in 2024

, “AI slop” is akin to “spam,” another term for nuisance digital content. And while AI slop abounds, it doesn’t describe all AI-generated content. Just that which seems to have little aesthetic or informational value or can even

potentially be harmful

.

Usage of the term “AI slop” increased by 9x in 2025

Our analysis found there were over 461,000 mentions of “AI slop” in 2024 across multiple sources, including X, Reddit, Pinterest, Twitch, forums, reviews, podcasts, blogs, comments, and news. Meanwhile,

by November 20, 2025, there were already about 2.4 million mentions, a 9x increase compared to the same time period in 2024.

According to the data, usage of “AI slop” first gained traction in August 2024, particularly on forums. Mentions then continued to grow in 2025,

spiking in late March following the launch of Ghibli AI

, ChatGPT’s free tool that generates images in the style of Studio Ghibli movies. At this point,

backlash grew significantly, with negative sentiment increasing nearly 20x

the average at the time. (More on that later.)

These posts on X presenting handmade work from human artists generated some of the highest engagement actions in the March 2025 discussion about AI slop.

In October, the AI slop discussion skyrocketed with an 87% increase in mentions and a 97% increase in engagement.

And as with the March mentions spike,

negative sentiment grew concurrently, reaching a high of 54%

and reflecting widespread doubt about AI-generated art.

How do people feel about AI slop? Not great.

“Slop” is inherently a negative term, so it’s no wonder it’s become the go-to label for low-quality output from generative AI tools. Still, there are AI slop champions out there claiming that it is what audiences are demanding. So who’s right?

According to our analysis,

audience backlash against AI slop is in full swing

and likely to continue into 2026. At the heart of it is the

desire for authenticity, originality, and human connection

, as highlighted in the March 2025 backlash against Ghibli AI. Studio Ghibli has long been known for meticulous craftsmanship and the dedication of human artists, especially Hayao Miyazaki, one of its co-founders. As a result, ChatGPT’s choice of model for its image tool seemed to confirm skeptics’ greatest fears that AI will capitalize on and then replace artists and human creativity.

Similar anxieties may have also driven the October 2025 surge in negative sentiment. That month,

Pinterest announced new tools

allowing users to limit the amount of AI-generated images that appear in their feeds.

The update followed

months of

criticism

that the platform was overrun with AI slop in the form of images, blog posts, and fake recipes. Additionally,

Taylor Swift

came under fire for

allegedly using AI-generated images

to promote her

Life of a Showgirl

album. These and other controversies have made AI slop a much-discussed topic as 2025 comes to a close.

So, what does the AI slop backlash mean for marketers?

Brands that have made craftsma

[Content truncated...]

---

## ✓ AI-Generated “Workslop” Is Destroying Productivity - YouTube

**URL:** https://www.youtube.com/shorts/eT0ZWhZPu_U

About

Press

Copyright

Contact us

Creator

Advertise

Developers

Terms

Privacy

Policy & Safety

How YouTube works

Test new features

© 2026 Google LLC

---

## ✗ https://medium.com/@genai.works/ai-slop-explained-why-low-quality-ai-content-is-everywhere-0cc31e0af5f4

**URL:** https://medium.com/@genai.works/ai-slop-explained-why-low-quality-ai-content-is-everywhere-0cc31e0af5f4

Error scraping: 403 Client Error: Forbidden for url: https://medium.com/@genai.works/ai-slop-explained-why-low-quality-ai-content-is-everywhere-0cc31e0af5f4

---

## ✓ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/SaaS/comments/1kgoilx?utm_source=chatgpt.com

Skip to main content

---

## ✓ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/MachineLearning/comments/1qcgh6d/d_classification_of_low_resource_language_using/

Go to MachineLearning

r/MachineLearning

•

Sikandarch

[D]  Classification of low resource language using Deep learning

I have been trying to solve classification problem on a low resource language. I am doing comparative analysis, LinearSVC and Logistic regression performed the best and the only models with 80+ accuracy and no overfitting. I have to classify it using deep learning model as well. I applied BERT on the dataset, model is 'bert-base-multilingual-cased', and I am fine tuning it, but issue is overfitting.

Training logs:

Epoch 6/10 | Train Loss: 0.4135 | Train Acc: 0.8772 | Val Loss: 0.9208 | Val Acc: 0.7408

Epoch 7/10 | Train Loss: 0.2984 | Train Acc: 0.9129 | Val Loss: 0.8313 | Val Acc: 0.7530

Epoch 8/10 | Train Loss: 0.2207 | Train Acc: 0.9388 | Val Loss: 0.8720 | Val Acc: 0.7505

this was with default dropout of the model, when I change dropout to 0.3, or even 0.2, model still overfits but not this much, but with dropout I don't go near 60% accuracy, long training introduces overfitting, early stopping isn't working as val loss continuous to decrease. On 10 epoch, I trained patience of 2 and 3. It doesn't stops. To prevent this I am not doing warmup step, my optimizer is below:

optimizer = AdamW([

{'params': model.bert.parameters(), 'lr': 2e-5},

{'params': model.classifier.parameters(), 'lr': 3e-5}

], weight_decay=0.01)

About my dataset,

I have 9000 training samples and 11 classes to train, data is imbalanced but not drastically, to cater this I have added class weights to loss function.

17 words per training sample on average. I set the max_length to 120 for tokens ids and attention masks.

How can I improve my training, I am trying to achieve atleast 75% accuracy without overfitting, for my comparative analysis. What I am doing wrong? Please guide me.

Data Augmentation didn't work too. I did easy data augmentation. Mixup Augmentation also didn't work.

If you need more information about my training to answer questions, ask in the comment, thanks.

Read more

Share

---

## ✓ Workers are wasting half a day each week fixing AI ‘workslop’ | IT Pro

**URL:** https://www.itpro.com/technology/artificial-intelligence/workers-are-wasting-half-a-day-each-week-fixing-ai-workslop?utm_source=chatgpt.com

(Image credit: Getty Images)

Share

Share by:

Copy link

Facebook

X

Linkedin

Bluesky

Share this article

Join the conversation

Follow us

Add us as a preferred source on Google

Newsletter

Subscribe to our newsletter

AI 'workslop' is forcing employees to work an extra four and a half hours each week to clean up mistakes, according to new research.

A

survey

of more than 1,100 US enterprise AI users from Zapier found that while 92% of workers say AI boosts their productivity, the average employee spends more than half a workday revising, correcting - and sometimes completely redoing - AI-generated outputs.

Three-quarters of respondents reported at least one negative consequence from low-quality AI outputs, including work rejected by stakeholders (28%), security incidents (27%), and customer complaints (25%).

Zapier noted that just 2% of respondents don’t need to revise what AI produces.

A key factor here lies in poor training, researchers noted. Employees without

AI training

are six times more likely to say AI makes them less productive.

While untrained workers spend less time on AI cleanup, they also report fewer productivity gains: just 69% say AI helps, compared with 94% of trained workers.

“The productivity gains from AI are real. 92% of workers feel them. But so is the cleanup work,” said Emily Mabie, senior AI automation engineer at Zapier.

Get the ITPro daily newsletter

Sign up today and you will receive a free copy of our Future Focus 2025 report - the leading guidance on AI, cybersecurity and other IT challenges as per 700+ senior executives

Contact me with news and offers from other Future brands

Receive email from us on behalf of our trusted partners or sponsors

“The companies seeing the best results aren't the ones avoiding AI. They're the ones who have invested in training, context, and orchestration tools that turn AI from a sloppy experiment into a managed process.”

The worst AI workslop offenders

Data analysis tops the workslop list, according to Zapier, with 55% saying data analysis and visualization projects require the most cleanup, followed by writing tasks at 46%.

Meanwhile, engineering, IT, and data roles average five hours per week fixing AI outputs, with 78% reporting negative consequences. Finance and accounting teams face the highest rate of negative consequences at 85%, averaging 4.6 hours of cleanup per week.

The time lost in fixing AI-generated outputs has a significant impact on bottom lines, according to Zapier. Workers spending more than five hours a week on AI cleanup tasks are more than twice as likely to report lost revenue, clients, or deals.

Zapier said better data quality and more robust infrastructure could go a long way in helping to improve the situation.

The study found that those with access to AI orchestration tools and comprehensive company context – so internal documentation, brand guides, project templates, or prompt libraries – said the technology does have a big positive impact on productivity.

“The solution isn’t fewer tools, it’s better infrastructure,” said Mabie. “Orchestration, training, and proper context convert AI from a vague experiment into a managed process where the extra cleanup is the cost of doing more meaningful work faster, rather than the cost of pretending you are.”

AI workslop is here to stay

The rise of AI workslop has become a recurring pain point for enterprises ramping up adoption of the technology.

A

report

from MIT researchers last year found that more than 40% of US-based workers had been given AI-generated content that “masquerades as good work but lacks the substance to meaningfully advance a given task”.

This, the study noted, was destroying productivity and harming perception of the technology in the workplace.

Certain professions are experiencing acute issues with this trend, such as those working in software development. A

recent study from CodeRabbit

, for example, shows that AI makes 1.7 times as many mistakes as human programmers.

The use of AI in software development has been one of the leading use-cases for the technology over the last three years, with developers reporting significant productivity boosts from AI code generation.

Research from Harness

in early 2025, however, found that these productivity gains are offset by the fact developers are having to drop tools and manually remediate faulty code, slowing down processes.

FOLLOW US ON SOCIAL MEDIA

Make sure to follow

ITPro on Google News

to keep tabs on all our latest news, analysis, and reviews.

You can also

follow ITPro on LinkedIn

,

X

,

Facebook

, and

BlueSky

.

TOPICS

Emma Woollacott

Emma Woollacott is a freelance journalist writing for publications including the BBC, Private Eye, Forbes, Raconteur and specialist technology titles.

Latest

Former Google engineer convicted after stealing AI, supercomputing secrets

News

Linwei Ding told Chinese investors he could build a world-class supercomputer

OpenAI se

[Content truncated...]

---

## ✓ YouTube chief says 'managing AI slop' is a priority for 2026

**URL:** https://www.cnbc.com/2026/01/21/youtube-chief-says-managing-ai-slop-is-a-priority-for-2026-.html

Skip Navigation

Markets

Business

Investing

Tech

Politics

Video

Watchlist

Investing Club

PRO

Livestream

Menu

Key Points

YouTube CEO Neal Mohan said in his annual letter that the company needs to get better at dealing with AI-generated content.

As artificial intelligence becomes more prevalent across video platforms, YouTube has to find ways to keep users and creators happy.

"It's becoming harder to detect what's real and what's AI-generated," Mohan wrote.

In this article

GOOGL

Follow your favorite stocks

CREATE FREE ACCOUNT

Neal Mohan, the CEO of YouTube speaks during a panel for the Summit for Democracy on March 30, 2023 in Washington, DC.

Anna Moneymaker | Getty Images

YouTube CEO Neal Mohan said reducing "AI slop" and detecting deepfakes are priorities for the

Google

-owned video site in 2026.

"It's becoming harder to detect what's real and what's AI-generated," Mohan wrote in his annual letter published Wednesday. "This is particularly critical when it comes to deepfakes."

With artificial intelligence penetrating every aspect of technology, Google has been investing heavily in building out the

infrastructure

to support new and growing workloads while also bolstering its Gemini models and adding AI features to its portfolio of business and consumer products.

But as one of the leading sources of user-generated content on the internet, YouTube is dealing with an explosion in the number of videos created by AI. The term AI slop

refers

to the mass of low-quality AI content that's showing up across social media platforms. In addition to YouTube, companies such as

Meta

and TikTok rely on recommendation systems powered by AI that surface personalized videos designed to keep users engaged for longer periods of time.

Mohan said the world is at an "inflection point," where "the lines between creativity and technology are blurring."

"To reduce the spread of low quality AI content, we're actively building on our established systems that have been very successful in combatting spam and clickbait, and reducing the spread of low quality, repetitive content," Mohan wrote.

He said that YouTube clearly labels videos created by AI products and requires creators to disclose if they've produced altered content. The company's systems also remove "harmful synthetic media" that violates its guidelines, Mohan wrote.

Critical to YouTube's growth among users, creators and advertisers is keeping the platform desirable for all parties involved.

In December, YouTube said it would be

expanding

its "likeness detection," which flags when a creator's face is used without their permission in deepfakes. The feature is being rolled out to millions of creators in the YouTube Partner Program.

Mohan's letter said the company will use AI as a tool and "not a replacement," adding that on average more than 1 million YouTube channels used its artificial intelligence creation technology daily in December.

The company is expanding the way creators can take advantage of AI, he said, including on YouTube's short-form video offering called Shorts, which competes with TikTok and Instagram Reels.

"This year you'll be able to create a Short using your own likeness, produce games with a simple text prompt, and experiment with music," he wrote.

Mohan described creators as "the new stars and studios," and said YouTube creators are "buying studio-sized lots in Hollywood and beyond to pioneer new formats and produce beautifully produced, must-see TV."  The company also wants to provide new ways for creators to earn, from "shopping and brand deals to fan funding features like Jewels and gifts."

Another priority, Mohan said, is making YouTube "the best place for kids and teens" and said this year the company plans to make it easier for parents to set up new kid accounts and to easily switch between them.

YouTube

said

in September that it's paid out more than $100 billion to creators, artists and media companies since 2021. Earlier in the year, analysts at MoffettNathanson

estimated

that If it was a stand-alone business, YouTube would be worth between $475 billion and $550 billion.

WATCH:

How Neal Mohan leads YouTube by putting creators first

watch now

VIDEO

1:04

01:04

How CEO Neal Mohan leads YouTube by putting creators first

Leaders Playbook

---

## ✓ The “AI stink” is real, and it’s costing brands — Raptive

**URL:** https://raptive.com/blog/the-ai-stink-is-real-and-its-costing-brands/

The “AI stink” is real, and it’s costing brands

Raptive

/

Last updated

August 22, 2025

If you’ve ever reluctantly removed em dashes from your writing to avoid

sounding like AI

, you know firsthand how generative AI is reshaping our perceptions of content. It’s impacting the way we write, the way we speak, and the speed at which content is created and consumed.

The ripple effect of rapid AI adoption is bound to touch ad performance. But how, and to what extent? Do audiences care who created the content they’re consuming?

To find out, we commissioned a study of 3,000 nationally representative U.S. adults to understand how people respond to content depending on who—or what—they think created it. Participants reviewed similar pieces of content, some of which were human-written and some AI-generated. We then measured their reactions to the content and to the ads shown alongside it.

The trust gap

At first glance, the findings may seem unremarkable: audiences don’t trust AI-generated content. But here’s the kicker—it doesn’t matter if the content was generated by AI or not.

As Anna Blender, our SVP, Data Strategy & Insights,

told Adweek

, “when people thought something was AI-generated, they rated that content much worse across metrics like trust and authenticity, regardless of whether it was really AI-generated or not.”

If people suspect something was written by AI, they automatically think less of it.

And the “stink” of that possibly-generated-by-AI content permeates everything around it, including ads.

Imagine dropping a perfectly good scoop of ice cream into a trash can. As soon as it’s in there, that formerly delicious ice cream becomes trash too.

The same thing happens to ads appearing in context with AI-generated content.

Readers may not know for certain how something was created, but even the perception of artificiality can erode brand equity. In a crowded media environment, the “AI stink” is real, and it’s contagious.

Avoid the AI stink

So what’s the takeaway from all of this for creators and publishers? Your content matters more than ever. In fact, people are

craving

it. Your personal stories, expert advice, and real-life experiences are a life raft for readers in a sea of AI slop.

While this study was designed to provide advertisers with a better understanding of how audiences respond to AI-generated content, there are plenty of insights applicable to creator businesses too.

As you continue creating, here are three things to keep in mind.

Emotional connection drives success

Clicks and conversions are great, but trust and authenticity go even further. “Realness” is something people can feel—and it’s something smart brands look for.

Context = brand safety

Brand safety goes beyond avoiding toxicity; positive reinforcement is important too. If your brand appears next to content that feels artificial, it can quietly erode its value, even if the content itself is innocuous. Perception matters. This is true for advertisers, and it’s true for you.

Your credibility is an asset

You’ve put in the work and you’ve built a community of people who trust you. That trust is something AI can’t fake and brands can’t buy. More than ever, they’ll look to creators like you to bring those audience relationships to the table.

As we move into a reality where we can’t always tell which voices are human and which are robots, creators and publishers still have the edge. You bring an irreplaceable human factor to the table, and readers continue to look to you for content they can trust.

Tags

Trending

,

Trends, insights and industry

---

## ✓ The Risk of AI Hallucinations: How to Protect Your Brand | NeuralTrust

**URL:** https://neuraltrust.ai/blog/ai-hallucinations-business-risk?utm_source=chatgpt.com

Back

The Risk of AI Hallucinations: How to Protect Your Brand

Martí Jordà

•

April 9, 2025

Contents

Generative AI models are designed to be

confident, even when they’re wrong

.

From chatbots inventing product specs to virtual assistants citing fake legal precedents,

AI hallucinations

have already caused

real-world embarrassment, financial loss, and legal trouble

. And as enterprises embed LLMs into customer support, search, and decision-making workflows, the

risks are only getting worse

.

This post unpacks the

business implications

of AI hallucinations,

why they happen

, and how your company can

prevent them

from damaging your brand or bottom line.

What Are AI Hallucinations (and Why Do They Happen)?

AI hallucinations

occur when a large language model (LLM) generates

false, misleading, or entirely fabricated content

that appears plausible, but isn’t grounded in factual data or sound logic. These aren't just minor inaccuracies, they're

confident, articulate misfires

that often go undetected until it's too late.

Why do LLMs hallucinate?

There are several contributing factors:

Statistical Prediction, Not Truth-Seeking

: LLMs like GPT-4 or Claude don’t “know” facts. They predict the next word based on statistical correlations, not factual correctness.

Overgeneralization from Training Data

: When models encounter edge cases or ambiguous queries, they may extrapolate from unrelated patterns, leading to incorrect responses.

Creative Completion Tendencies

: Models often attempt to “fill in the blanks” when they sense incomplete prompts. This is great for fiction, but dangerous in business contexts.

Contextual Drift

: In longer conversations or interactions, models may subtly shift away from initial grounding, increasing the chance of errors.

Poor Prompting or Fine-Tuning

: Misaligned prompts or insufficiently constrained models can introduce unintended behavior.

In short, hallucinations are an

inherent risk

of using probabilistic models in deterministic domains.

Real-World Examples of Hallucinations Hurting Businesses

Hallucinations aren’t theoretical or technical bugs. They’re

business threats

already causing

tangible damage

.

Legal Hallucination (Mata v. Avianca Airlines)

In a now-infamous case,

a lawyer used ChatGPT to generate legal citations

, only to discover that the model had

completely fabricated court decisions

. The firm faced public embarrassment and judicial sanctions.

Helpdesk Chatbot Hallucinates Refund Policy

A Canadian airline’s chatbot promised a refund to a customer

based on a

policy that didn’t exist

. A court later ruled the airline was liable, stating that AI-powered agents are extensions of the company’s voice.

NYC AI Chatbot Provides Incorrect Legal Guidance to Businesses

New York City’s AI chatbot

misinformed small businesses

, wrongly stating that employers could keep tips and landlords could discriminate based on income. The incident raised concerns about the dangers of deploying AI in legal and regulatory advisory roles.

Why AI Hallucinations Are a Business Risk

Even a

single hallucination

can have wide-reaching effects. The risks span multiple departments, from legal to marketing to finance.

Brand Trust Erosion

Your AI is part of your brand. When a customer-facing model delivers incorrect information, it

erodes credibility

, not just in the AI, but in your entire business. Trust is easy to lose and hard to regain.

Legal Liability

Incorrect AI-generated outputs about pricing, contracts, HR policies, or legal/medical matters can land you in hot water. Companies are being

held accountable for the actions of their AI agents

, even when the outputs are unintentional.

Financial Impact

Hallucinated financial data or market insights can directly lead to

poor business decisions

, rejected transactions, incorrect billing, and revenue loss.

Compliance Failures

Under regulations like the EU AI Act, Colorado’s AI Accountability Act, or HIPAA, AI outputs must meet standards of fairness, accuracy, and explainability. Hallucinations can easily put your systems

in violation

.

High-Risk Use Cases That Must Be Monitored Closely

Some use cases carry a

disproportionate level of risk

. Hallucinations in these contexts can go from

inconvenient to catastrophic

.

Customer-facing chatbots

: The front line of your brand. Errors here are publicly visible.

Automated documentation generation

: Mistakes in contracts, product documentation, or policies create legal and compliance issues.

Internal knowledge assistants

: HR, Legal, and Finance bots must not invent answers that influence sensitive business decisions.

Search + RAG interfaces

: Hallucinated citations can undermine the whole point of grounding.

Autonomous AI agents

: Systems that take actions based on faulty information can create cascading business failures.

How to Protect Your Brand from AI Hallucinations

You can't eliminate hallucinations completely, but

[Content truncated...]

---

## ✓ The Elusive ROI of AI at Work: A Study by BetterUp Labs and Stanford | Amy L. Cole posted on the topic | LinkedIn

**URL:** https://www.linkedin.com/posts/amycoleaz_ai-generated-workslop-is-destroying-productivity-activity-7375897394099453952-Xxzo?utm_source=chatgpt.com

Amy L. Cole

4mo

Edited

Report this post

The ROI of AI at work is apparently still pretty elusive. A big culprit is “workslop”, the AI-generated stuff that looks fine on the surface but is generic and hollow, and basically pushes the real thinking onto coworkers.

BetterUp Labs and Stanford found that 41% of people have run into this problem, and it wastes almost two hours each time re-doing the work. Beyond the wasted time, it erodes trust, teamwork, and productivity.

Much of this comes from top-down “just use AI” mandates without much guidance. If leaders really want AI to help, they need to set the tone, show how to use it thoughtfully, set clear quality standards, and encourage a Pilot mindset: one that blends optimism with accountability.

See our Labs’ HBR article published this week, linked below.

Kate Niederhoffer

,

Gabriella Rosen Kellerman, MD

, Angela Lee, Alex Liebscher, Kristina Rapuano, and

Jeff Hancock

https://lnkd.in/gaDivbRV

24

5 Comments

Like

Comment

Share

Copy

LinkedIn

Facebook

X

Amit Patel

Trusted Advisor & Fractional Leader | Business & AI Strategist | Organizational Agility  | Future Of Work  | Transformation 📈

4mo

Report this comment

Amy, this hits exactly what we're seeing with clients. The "workslop" term is perfect - executives wonder why their AI investment isn't paying off while teams quietly spend hours fixing generic outputs.

The trust erosion is the real killer. When someone gets polished but hollow AI work, it changes how they view that colleague's judgment. That's organizational capital being destroyed.

Too many companies treat AI like a light switch - flip it on, expect transformation. The successful rollouts start with leaders who understand the tool's blind spots and model thoughtful usage themselves.

The pilot mindset you describe - optimism with accountability - requires intellectual humility. Create space for smart experimentation while maintaining quality standards that actually matter.

That 41% figure is sobering but unsurprising. Human judgment remains irreplaceable, especially in knowing when and how to deploy these tools effectively.

Like

Reply

3 Reactions

4 Reactions

Seth Pride

Senior Manager at Centric Consulting

3mo

Report this comment

This is a great point. Recently heard of a team who used AI for all of their data analysis for a client presentation, the client’s feedback was that it “felt like the team was just reading the slides” instead of helping us understand what they found.

Like

Reply

1 Reaction

See more comments

To view or add a comment,

sign in

---

## ✗ https://medium.com/%40cadetnajeebullah/ai-slop-the-biggest-threat-to-quality-content-in-2025-and-how-to-combat-it-022db965cad8?utm_source=chatgpt.com

**URL:** https://medium.com/%40cadetnajeebullah/ai-slop-the-biggest-threat-to-quality-content-in-2025-and-how-to-combat-it-022db965cad8?utm_source=chatgpt.com

Error scraping: 403 Client Error: Forbidden for url: https://medium.com/%40cadetnajeebullah/ai-slop-the-biggest-threat-to-quality-content-in-2025-and-how-to-combat-it-022db965cad8?utm_source=chatgpt.com

---

## ✓ OpenAI Losing Billions on AI Slop Videos - YouTube

**URL:** https://www.youtube.com/watch?v=nTDS5r5fk_k

About

Press

Copyright

Contact us

Creator

Advertise

Developers

Terms

Privacy

Policy & Safety

How YouTube works

Test new features

© 2026 Google LLC

---

## ✗ https://medium.com/%40pamir_93399/authenticity-gap-the-frustrating-side-of-ai-slop-1bf78be436fe?utm_source=chatgpt.com

**URL:** https://medium.com/%40pamir_93399/authenticity-gap-the-frustrating-side-of-ai-slop-1bf78be436fe?utm_source=chatgpt.com

Error scraping: 403 Client Error: Forbidden for url: https://medium.com/%40pamir_93399/authenticity-gap-the-frustrating-side-of-ai-slop-1bf78be436fe?utm_source=chatgpt.com

---

## ✗ https://www.producthunt.com/topics/artificial-intelligence

**URL:** https://www.producthunt.com/topics/artificial-intelligence

Error scraping: 403 Client Error: Forbidden for url: https://www.producthunt.com/topics/artificial-intelligence

---

## ✓ AI Slop: Are We Ready for It? - testRigor AI-Based Automated Testing Tool

**URL:** https://testrigor.com/blog/ai-slop/

Megana Natarajan

AI in Testing

One of the biggest technological advancements of the last decade has been the meteoric rise of generative AI. We have surpassed the stages of being amazed by AI’s capability to complete simple sentences to watch it with trepidation as it creates photorealistic images, writes code, produces marketing copy, and even replicates human speech, all in a matter of a few short years. But like every coin has two sides, this technological change came with its own range of drawbacks. One of the main new issues is what many call “AI Slop”.

The phrase “AI Slop” refers to the low-quality, mass-produced, algorithmically generated content that is prevalent online. This covers code, images, videos, and text that appear polished on the surface. However, it lacks originality, value, substance, and accuracy. It is content produced in haste, in large quantities, and often with nearly zero human intervention. And this sludge saturates the internet, people and organizations must ask themselves:

Are we really ready for the consequences of AI Slop?

Key Takeaways:

AI Slop is the low-quality, mass-produced content generated by AI for speed and volume, not necessarily for depth or accuracy.

It manifests across media: text, images, code, audio, and social-media noise, degrading the quality and reliability of digital ecosystems.

The incentives driving AI Slop—cheap generation, algorithmic engagement, and financial gain—make it a systemic problem, not just a nuisance.

Critical risks include trust erosion, misinformation, code fragility, and a self-reinforcing feedback loop where slop begets more slop.

The feedback loop problem means AI-generated content increasingly trains future models, risking a decline in overall content quality.

In software development, AI-assisted code can produce “vibe coding” — readable but shallow, risky, or incomplete without proper validation.

Strong governance, human oversight, and testing pipelines are essential to safeguard against AI Slop.

testRigor, with its human-readable tests and robust end-to-end validation, offers a practical tool for catching AI-generated errors, preventing fragile automation, and enforcing quality.

Ultimately, while AI accelerates content creation, quality remains a choice — and organizations must build infrastructure to filter, test, and validate what AI produces.

This blog will go into what AI Slop is, why it is so popular, the risks it poses, and how organizations can stay safe. Additionally, we will also see how AI-powered tools help teams to protect against the negative impact of AI-generated low-quality output.

What Is AI Slop? Understanding the Rise of Low-Quality AI Content

AI Slop is much more than just “bad content.” It is a systemic byproduct of generative AI ecosystems, where users find it difficult to differentiate between AI-generated noise and real work. Platforms obviously reward engagement over quality, and AI content is quick and inexpensive to generate.

AI slop includes a range of outputs:

Low-Quality AI-Generated Text

Articles, blogs, product descriptions, emails, and scripts are generated in a matter of seconds. These often contain repeated phrases, generic language, errors, or hallucinations. They might appear to be clear and readable, but they lack depth and are not supported by facts.

Synthetic Images and Videos

Anyone can now generate stylized or photorealistic images with AI art generators. But a lot of the output is repetitive or incoherent. Think in the lines of uncanny-valley faces, odd artifacts, surreal proportions, extra fingers, and mismatched lighting.

Sloppy AI-Generated Code

Code-writing generative AI tools can produce useful snippets, but they often:

Inability to understand business logic.

Ignore edge cases.

Create brittle tests.

Introduce security flaws.

Produce code that “works” now but breaks later.

This is what is called “

vibe coding

”, AI-generated code that is based on probabilistic patterns rather than true understanding.

AI-Generated Audio & Voice Clones

While inexpensive tools continue to generate robotic pacing, unnatural inflection, and wrong emphasis, synthetic voices are swiftly improving. These increase the risk of deepfakes and contribute to a general deterioration in media quality.

Algorithm-Driven Social Media Noise

Platforms reward clicks rather than value addition. AI makes it easier than ever to create:

Buzzword-heavy posts

Very typical inspirational quotes

Low-effort viral bait

Fake engagement

The result is a digital environment drowned in filler.

Why AI Slop Is Exploding: The Perfect Ecosystem for Low-Quality Content

The Barrier to Creation Has Never Been Lower

Ten years ago, it took skill, time, and effort to write a good blog, illustration, or short film. A smartphone user can now generate results that are almost professional in a matter of minutes.

It is great that creating has become democratized; anyone can do it. But here quantity overwhelms q

[Content truncated...]

---

## ✓ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/ProductHunters/comments/1oo6skv/support_us_to_remove_ai_slop/

Go to ProductHunters

r/ProductHunters

•

Wise-Thanks-6107

Support us to remove AI slop!!

We just launched Codoki on Product Hunt today! 🚀🚀🚀

Would really appreciate your support and feedback on our launch. Every comment and upvote helps us reach more developers who care about code quality and AI safety.

https://www.producthunt.com/products/codoki

Read more

Share

---

## ✓ More than 20% of videos shown to new YouTube users are ‘AI slop’, study finds  | AI (artificial intelligence) | The Guardian

**URL:** https://www.theguardian.com/technology/2025/dec/27/more-than-20-of-videos-shown-to-new-youtube-users-are-ai-slop-study-finds?utm_source=chatgpt.com

The Super Cat League features human-like cats in (AI-generated) bizarre scenes.

Illustration: @SuperCatLeague/YouTube

View image in fullscreen

The Super Cat League features human-like cats in (AI-generated) bizarre scenes.

Illustration: @SuperCatLeague/YouTube

AI (artificial intelligence)

This article is more than

1 month old

More than 20% of videos shown to new YouTube users are ‘AI slop’, study finds

This article is more than 1 month old

Low-quality AI-generated content is now saturating social media – and generating about $117m a year, data shows

Aisha Down

Sat 27 Dec 2025 17.00 GMT

Last modified on Tue 6 Jan 2026 11.38 GMT

Share

More than 20% of the videos that YouTube’s algorithm shows to new users are “AI slop” – low-quality AI-generated content designed to farm views,

research has found

.

The video-editing company Kapwing surveyed 15,000 of the world’s most popular YouTube channels – the top 100 in every country – and found that 278 of them contain only

AI slop

.

Together, these AI slop channels have amassed more than 63bn views and 221 million subscribers, generating about $117m (£90m) in revenue each year, according to estimates.

The researchers also made a new

YouTube

account and found that 104 of the first 500 videos recommended to its feed were AI slop. One-third of the 500 videos were “brainrot”, a category that includes AI slop and other low-quality content made to monetise attention.

The findings are a snapshot of a rapidly expanding industry that is saturating big social media platforms – from X to Meta to YouTube – and defining a new era of content: decontextualised, addictive and international.

A Guardian analysis

this year found that nearly 10% of YouTube’s fastest-growing channels were AI slop, racking up millions of views

despite the platform’s efforts

to curb “inauthentic content”.

The channels found by Kapwing are globally distributed and globally watched. They have millions of subscribers: in Spain, 20 million people, or nearly half the country’s population, follow the trending AI channels. AI channels have 18 million followers in Egypt, 14.5 million in the US, and 13.5 million in Brazil.

Bandar Apna Dost

, the most-viewed channel in the study, is based in India and now has 2.4bn views. It features the adventures of an anthropomorphic rhesus monkey and a muscular character modelled off the Incredible Hulk who

fights demons

and travels on a helicopter made of tomatoes. Kapwing estimated that the channel could make as much as $4.25m. Its owner did not respond to a query from the Guardian.

Rohini Lakshané, a researcher on technology and digital rights, said Bandar Apna Dost’s popularity most likely stems from its absurdity, its hyper-masculine tropes and the fact that it lacks a plot, which makes it accessible to new viewers.

Pouty Frenchie

, based in Singapore, has 2bn views and appears to target children. It chronicles the adventures of a French bulldog – driving to a candy forest, eating crystal sushi – many of them set to a soundtrack of children’s laughter. Kapwing estimates it makes nearly $4m a year. Cuentos Facinantes, based in the US, also appears to target children with cartoon storylines, and has 6.65 million subscribers – making it the most-subscribed channel in the study.

Meanwhile,

The AI World

, based in Pakistan, contains AI-generated shorts of catastrophic flooding in Pakistan, with titles such as Poor People, Poor Family, and Flood Kitchen. Many of these videos are set to a soundtrack called Relaxing Rain, Thunder & Lightning Ambience for Sleep. The channel itself has 1.3bn views.

It’s hard to say exactly how significant these channels are compared with the vast sea of content already on YouTube. The platform does not release information on how many views it has yearly, or how many of these are from AI content. In a comment to the Guardian, a YouTube spokesperson said they had terminated one “AI slop” channel identified in Kapwing’s study, and removed others from its monetisation programmes.

But behind these uncanny scenes of candy forests and disasters is a semi-structured, growing industry of people trying to find new ways to monetise the world’s most powerful platforms using AI tools.

“There are these big swathes of people on Telegram, WhatsApp, Discord and message boards exchanging tips and ideas [and] selling courses about how to sort of make slop that will be engaging enough to earn money,” said

Max Read

, a journalist who has written extensively on AI slop.

“They have what they call niches. One that I noticed recently is AI videos of people’s pressure cookers exploding on the stove.”

While creators of AI slop are everywhere, Read said that many come from English-speaking countries with relatively strong internet connectivity, where the median wage is less than the amount they can make on YouTube.

“It’s mostly sort of middle-income countries like Ukraine, lots and lots of people in India, Kenya, Nigeria, a fair numb

[Content truncated...]

---

## ✓ https://www.oecd.org/content/dam/oecd/en/publications/reports/2025/06/the-effects-of-generative-ai-on-productivity-innovation-and-entrepreneurship_da1d085d/b21df222-en.pdf?utm_source=chatgpt.com

**URL:** https://www.oecd.org/content/dam/oecd/en/publications/reports/2025/06/the-effects-of-generative-ai-on-productivity-innovation-and-entrepreneurship_da1d085d/b21df222-en.pdf?utm_source=chatgpt.com

%PDF-1.6

%����

1 0 obj

<<

/Contents 2 0 R

/CropBox[0 0 595.32 841.92]

/Group

<<

/CS/DeviceRGB

/S/Transparency

/Type/Group

>>

/MediaBox[0 0 595.32 841.92]

/Parent 3475 0 R

/Resources 126 0 R

/Rotate 0

/StructParents 2

/Tabs/S

/Type/Page

>>

endobj

2 0 obj

<<

/Filter/FlateDecode

/Length 2906

>>

stream

x��Z�n�860��g�o��4H��(j1 u�K�I��Iwv:X��lk�ZII&��/0Ϸ�R��d�����,^���I�����t��?���[���$���ˮ~���]%;��q:�i6�9�~_b�a�&��?���o3�����;a�@@9

�t��,�q�E̝

�Vj��|�����I'n!	��&s7��3��

#���������e�� 8Mr4���9u��UU6l���Y��1~�9��,�.-�y�F���lLY�i"}�,�u����7G$y25z�Y';4��m䤫��6�Ś�V�i�(��OI����[o�y@�� ��n�,��o�9�Z�h�R�dE��M�E�m�5�\ڊ�#8��;�44�{�z�z���v�K�f���}��.ad��o�� r���������V�������u�kQ�~&��U3����Ԟ�_�K���y\a�Bm���^µ��TE�"ƖL��'�ha�M��

ʷ��VCΟ@�(��*�O~@�*���'�dM��_����:�`?mDl���Fa�L���`��s��4�x��zIn�G�M&�7�����4�6S�)s�{4+�f�������b7�K`�I0�E�i5n�_&\����;j?����膺_b͟a-�]�t_�!G�<Ԇ��3I�r9�u�nyU�?0{����׍���_b"��N� �m�ג�~�0|�ZFr9��5���w_

�F-^�L!��䒰:x���Y�	��m���ǖ��w

��e2�zϲ*w�T�6�z����os?{�J��g�#�πUs��wz<

endstream

endobj

3 0 obj

<<

/Contents 4 0 R

/CropBox[0 0 595.32 841.92]

/Group

<<

/CS/DeviceRGB

/S/Transparency

/Type/Group

>>

/MediaBox[0 0 595.32 841.92]

/Parent 3475 0 R

/Resources 127 0 R

/Rotate 0

/StructParents 3

/Tabs/S

/Type/Page

>>

endobj

4 0 obj

<<

/Filter/FlateDecode

/Length 1695

>>

stream

x��Y�n�6�o?JCM�EI@Q����]�d��b(�A�e�K,e��,}�=��jwGIv�����]�Xy$���xwTY���E<+�?���"��'�w�iv��7��Jz��r���*K{���v'�<�_�8:v������a^�qW»�J�%x(�0��`y�y�c'�L;�C����b�E�9L0�q� ,��:�ʇG�Mם���g�>��)�9�6�tZe3K;�,e���D	�Ѵ���wa�����9��bO�� ŕT��jG4���o�������~/�$oA

�� U��!�G,:���u���۳�u�h�B[g���M���j�1;=;�}k����H�pd��3|0z�ae��

�y���Y4��E�g��.r69���i�T�˵vг��~| Px������+`E��χ���(���Q�0ˊGFAɂOts��=3C_{L�����v�v *v=�ow�El),�%m��G��Fh$^�ka/�I>�&�JEc[41�I4���Y�Z��O[�'����((;K7��)��.��;(�F�����[��B$yXuK0���Z��s.��*���z�{r/�|OP>WphX鱠(�L������hȜޫ8]ZI�=:�V4s��S��E��x��ь{��+Q��.���2�/�u���1�~��U@�I�eCpl����	ٔ�KΩ!x�����Y>f�{xx�h��@q�;���N��9OL�p�k�[hv�y�˕��R�:�^bߜޥu�9h��

%e�Y!���cX*����)�Ox�����5#b��KP$Y�]ߊde_�¨#@�X0!��N0�GX��rq�F��

*â@�d��;Ғ�Q���m�]��Qn�����)�f���@qd

>

/MediaBox[0 0 595.32 841.92]

/Parent 3475 0 R

/Resources 128 0 R

/Rotate 0

/StructParents 4

/Tabs/S

/Type/Page

>>

endobj

6 0 obj

<<

/Filter/FlateDecode

/Length 2580

>>

stream

x��\}o�8����39]��ݑV+1�vz���ZfN���D!�h��BJw>�}�{�0@

!���(�c�������rޞ���� ���v��O�����t��y��,9��Ɠ~:�N��_R�z������]tZ�h���5�DDŊ

�FpI�d4fqly��

�j�T�^M���Q����[�����(fD�F<��c���{H��Sm��6%���e�g&��oL'.Ĭ[�C(� B��3��N�)� ���Y�һ'J@�̗M9���0Qm�'͋��R�ٰ�X@wf���������'�kʲ@��)ڳ�F&��=�����3_�@���K$}����>#�3�,f� Kd���z��N����X�؉['X�F���<��ϕ��F꣒P\���\o$7�W���,���,Fz���ʢ|%ȯ�ӎ��U:c��+J�L޵G����R�ui[��WXb��k8/��&���Z�E���t�<g�]%I���%�8�?�C��Um��U�esڣ �H�aJ���ȼ�0�ڣ��\��*�e

�b+6��@Kܫ��s��cC�QnqOб�O�/�a>�����R�taz��S�x�E���:��5���h��Q�׆`m�4p��O�ֻ�9��� i�:ߵJ��K��-s�s���5x+�XI0��]Xǩr��r�����,���r����P;_�Df�#t^�~��,������R���r5Ҿ������5����;�I����ؙ�B�ɍCf9��2c����%ΙJܘ�t�ߒ3jT5A7��va��x�z󙓨+��z;]R��ub��/"�u�N���.f����

s����{�gߍS�+bn��t�����=8�����j�7�(�8H6rK�O|��f}M��,�g6��L�;u���<|k��>#v��)�곂U�Y�

y֑

Y�)d�5��)�"�O�&���W|D��e��l��7ͼ�����)d�=S|co��L�fƔ�H�U��Ǵ?B'.�r�t��k��3:b`��esʡ �H�P���>�u�YT�m�p��VdwȽP�u�����(����יִ����������׌�(��Z5��m@Ǻm{�^�gX_�_]�.�/%�P�~�G� ����l��!'Tk�*��6A�]@G�S�����W�����"���]��1ɢށ'nr��n5`M�rб���H)|�E��=m���gnY�gߞ�9�?	��6%��|9v�I�w���U,�H��d�`����������*��`wБ�{�8�g�[�_�$���b�m6kFV�#V�eQ/>�;b�F*,

>�ħ\����+\8��B��_�6V�=�mt�؂j���!N�۹_�<�v=F�#�t�#��_\.��zx��`��j���

���R�4d, �Uf�e��g|�q�L��(�0�+1�b�G|���틙�0t��Y���v%8�l��p$���ީ{��Oe���k�D�.}ʶ�W�I��rP�'��zC������dt���?opom5 i��0��VT�ʓ!?�5�PT�dK���ථ�v���,c*$R2>�1��4f��@ex�NY����]6L��7R�Av�c���+���G��V[�L�5&�D&,r&���70�:��� �����|V������+7����:3x�P.�0�3��܄'0̫�Y2�a~2*���i�&�҇�(d�Q~�3qQW�;Pىw,�u��l��Q�;"

endstream

endobj

7 0 obj

<<

/Contents 8 0 R

/CropBox[0 0 595.32 841.92]

/Group

<<

/CS/DeviceRGB

/S/Transparency

/Type/Group

>>

/MediaBox[0 0 595.32 841.92]

/Parent 3475 0 R

/Resources 129 0 R

/Rotate 0

/StructParents 23

/Tabs/S

/Type/Page

>>

endobj

8 0 obj

<<

/Filter/FlateDecode

/Length 7284

>>

stream

x��]IoI�&�7_

�xh̐+���\�l�v{�d�]]�AJJ-(Iɦ�R�'�q.���-���l1T

����_lo�ދ������:j��g�۶::����l�������I��Cuz~U���ճ��a����긞���?o�x�'Q��E.��0-�(�p�'R%�R�e!K1��O���Փ���<{)�BD��<���fi$�nq>̳"R9�*+���O���ˇ�����%�}q-�G�Obz���Փ���?�_������d�E2s%p�.�I���J� HEJ�8N�X��5����E)�g�%ɏ�.9,{$�QCWɤ�h{k��r���^n������t��~��_[��"�>����g�����������q>��4V�p�^���S�3��w������=���&�n�������5���%�{���·���$ʲgV&���(�4�q��������O�f�?7m�\~��l��rA9,�ږ�$J

�ڧ�kR��N�)�(F��Zs�

[Content truncated...]

---

