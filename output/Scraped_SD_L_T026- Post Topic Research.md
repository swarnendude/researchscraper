# Scraped Content

Total URLs: 27

---

## âœ— https://medium.com/%40dougliles/ai-agent-workflow-orchestration-d49715b8b5e3

**URL:** https://medium.com/%40dougliles/ai-agent-workflow-orchestration-d49715b8b5e3

Error scraping: 403 Client Error: Forbidden for url: https://medium.com/%40dougliles/ai-agent-workflow-orchestration-d49715b8b5e3

---

## âœ“ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/LangChain/comments/1mrj07e/anyone_building_an_agent_platform_with_langchain/

Go to LangChain

r/LangChain

â€¢

SatisfactionWarm4386

PortuguÃªs (Brasil)

à¤¹à¤¿à¤¨à¥à¤¦à¥€

Ğ ÑƒÑÑĞºĞ¸Ğ¹

Magyar

à¹„à¸—à¸¢

Deutsch

Dansk

Italiano

Anyone building an â€œAgent platformâ€ with LangChain + LangGraph or other framework?

Iâ€™m trying to design an

Agent middle layer

inside my company using LangChain + LangGraph. The idea is:

One shared platform with core abilities (RAG, tool orchestration, workflows).

Different teams plug in their own agents for use cases (customer support, report generation, SOP tasks, etc.).

Basically:

a reusable Agent infra instead of one-off agents.

Has anyone here tried something similar? Curious about:

What worked / didnâ€™t work in your setup?

How you kept it flexible enough for multiple business scenarios?

Any best practices or anti-patterns with LangGraph?

Read more

Share

---

## âœ“ Orchestrate Book - Swarnendu De

**URL:** https://www.swarnendu.de/orchestrate-book/

Apress Publishers

Orchestrate â€“ Mastering Multi-Agent AI in Business Automation

A framework-driven guide to design, orchestrate, and scale multi-agent AI workflows for real business impact.

About The Book

Over the last few years, Iâ€™ve helped startups, SMBs, and enterprises turn AI hype into working systems â€“ from multi-agent customer support platforms to fully automated decision pipelines. In every case, success came down to one thing:

orchestration

.

This book distils the frameworks, technical patterns, and business strategies Iâ€™ve used to take AI from whiteboard to market launch. Unlike most AI books,

Orchestrate

doesnâ€™t stop at â€œwhatâ€™s possibleâ€ â€“ itâ€™s a

practical, architecture-first playbook

with real case studies, implementation guides, and scale-up strategies.

Youâ€™ll learn how to:

Map business goals to AI capabilities.

Design agent-based architectures that work in the real world.

Integrate RAG, LLMs, and external APIs for maximum leverage.

Deploy and maintain AI systems that stay reliable under load.

Whether youâ€™re a

founder, CTO, or product manager

, this is the missing manual for turning AI from an experiment into a competitive advantage.

6 Things This Book Will Teach You

While the full table of contents will be revealed closer to launch, hereâ€™s a preview of whatâ€™s inside:

Multi-Agent System Design

Architecting agent workflows for complex, interdependent tasks.

AI Orchestration Frameworks

Applying tools like LangChain, AutoGen, and CrewAI to coordinate intelligence.

Retrieval-Augmented Generation (RAG)

Leveraging your own data to make AI accurate and context-aware.

Domain-Specific LLM Strategies

Customising large language models for industry use cases.

Integration & Automation

Connecting AI agents to APIs, enterprise systems, and decision engines.

Scaling & Reliability

Ensuring AI workflows perform under real-world load, across teams and markets.

and much, much moreâ€¦

Who This Book Is For

Orchestrate

is designed for people who arenâ€™t just curious about AI â€“ they need it to deliver results. If youâ€™re in one of these roles, this book will save you months (or even years) of trial and error:

Startup founders

looking to embed AI into their products from day one.

CTOs & engineering leaders

architecting AI systems for scale and reliability.

Product managers

who want to translate business goals into AI-powered features.

Enterprise transformation leaders

driving operational efficiency with automation.

AI consultants & solution providers

seeking structured, repeatable delivery frameworks.

About The Author

Iâ€™m

Swarnendu De

â€“ a SaaS & AI product strategist, technology leader, and co-founder of

AllRide Apps

and

Innofied Solutions

. Over the past 18 years, Iâ€™ve worked with startups, SMBs, and Fortune 500 companies to design, build, and launch

100+ SaaS and AI products

â€“ many of which now serve millions of users and generate millions in revenue.

Iâ€™ve led AI automation projects that range from

multi-agent customer service systems

to

enterprise-scale decision workflows

, integrating tools like LangGraph, AutoGen, and RAG architectures into production-grade platforms. Iâ€™ve built custom LLM-based solutions as well as APIs like OpenAPI, Anthropic, Perplexity, Gemini, and AWS Bedrock.

Iâ€™ve taught over

10,000 students

online, spoken at global tech events, and helped founders worldwide take AI ideas from a whiteboard to a working, revenue-driving product. With

Orchestrate

, Iâ€™m sharing the same frameworks, architectures, and real-world lessons I use to deliver results for clients every day.

Build Your Next AI Product With My

AI Success Strategy Frameworkâ„¢

Discuss Your Project

Join 600+ successful products.

200+ Reviews

---

## âœ— https://medium.com/%40roberto.g.infante/the-state-of-ai-agent-frameworks-comparing-langgraph-openai-agent-sdk-google-adk-and-aws-d3e52a497720

**URL:** https://medium.com/%40roberto.g.infante/the-state-of-ai-agent-frameworks-comparing-langgraph-openai-agent-sdk-google-adk-and-aws-d3e52a497720

Error scraping: 403 Client Error: Forbidden for url: https://medium.com/%40roberto.g.infante/the-state-of-ai-agent-frameworks-comparing-langgraph-openai-agent-sdk-google-adk-and-aws-d3e52a497720

---

## âœ— https://www.producthunt.com/categories/ai-agent-automation

**URL:** https://www.producthunt.com/categories/ai-agent-automation

Error scraping: 403 Client Error: Forbidden for url: https://www.producthunt.com/categories/ai-agent-automation

---

## âœ“ Businesses must control AI agent actions and identities â€“ or face the consequences, says Palo Alto Networks EMEA CISO | IT Pro

**URL:** https://www.itpro.com/security/agentic-ai-poses-major-challenge-for-security-professionals-says-palo-alto-networks-emea-ciso

(Image credit: Getty Images)

Share

Share by:

Copy link

Facebook

X

Linkedin

Bluesky

Share this article

Join the conversation

Follow us

Add us as a preferred source on Google

Newsletter

Subscribe to our newsletter

Agentic AI projects are likely to fail at a rate far higher than currently predicted and present a major challenge to cybersecurity operations, according to an information security expert.

Haider Pasha, EMEA CISO at Palo Alto Networks, told

ITPro

that the benefits of

agentic AI

would be outweighed by the risks if

chief information security officers (CISOs)

donâ€™t employ strict strategic and technical controls over the technologyâ€™s deployment.

Gartner predicts

40% of agentic AI projects will fail by 2027

and Pasha said this wasnâ€™t surprising.

â€œI actually think itâ€™s low, personally I think it's going to be a lot higher because, like gen AI that we saw from the MIT report, I think a couple of years from now we're going to see a lot more agentic projects that will fail.

â€œBecause the governance, and the security, the tools, the processes and the mindset shift towards really controlling what that system is supposed to do, all of those things will not necessarily be looked after.â€

This is partly due to persistent confusion over the exact definition of agentic AI, Pasha explained, with executive interest in the technology being driven by internet hype or newspapers rather than clear business use cases.

He pointed to findings that 93% of enterprises are looking to adopt agent-based systems, per MuleSoft and Deloitte Digitalâ€™s

2025 Connectivity Benchmark Report

, as evidence of this interest.

Get the ITPro daily newsletter

Sign up today and you will receive a free copy of our Future Focus 2025 report - the leading guidance on AI, cybersecurity and other IT challenges as per 700+ senior executives

Contact me with news and offers from other Future brands

Receive email from us on behalf of our trusted partners or sponsors

Early evidence suggests that agentic AI could deliver tangible benefits for businesses, with Capgemini

having recently projected

the technology could deliver $450 billion in economic value.

But Pasha cautioned against diving headfirst into agentic AI adoption without clear ideas of how it could benefit them and the impact it would have on their cybersecurity.

â€œI think, as CISOs, we need to do a better job of removing the hype and really un-teaching and teaching the board about what cybersecurity and cyber resilience really means in the age of agentic AI, generative AI, and so on,â€ Pasha said.

Organizations looking to deploy AI agents at scale will need to secure them in the runtime, he advised, with security leaders needing to examine agentic dependencies such as API calls, MCP connections, and SDKs.

â€œWhat you ultimately need to do, at a behavioral level, is treat it like an intern,â€ Pasha told

ITPro

.

â€œThatâ€™s the simplest way I'm explaining it to my peers, is I'm saying â€˜Look treat it, like an intern. What level of privileges would you give an intern? How do you secure the identity, the access, the device thatâ€™s being used, the workload it can access, the tools it can call?â€

This can be achieved at the network layer using firewalls or at the code level â€“ with developer code within agents probed for vulnerabilities.

Itâ€™s this functionality that Palo Alto Networks sought through its

recent acquisition of Protect AI

, Pasha said, along with â€œred teaming on demandâ€ in which runtime security analysis can be carried out on a tool while itâ€™s still being coded.

AI Agents are full of vulnerabilities

All of this will be necessary to overcome inherent limitations within agentic AI systems such as memory misuse, Pasha explained.

This is a term for an attack in which hackers with admin-level privileges to an agentic system poison its fundamental instructions.

For example, an attacker could alter an agentic flight booking system to always provide specific users flights for free, then book a chartered flight to Dubai without the system flagging the journey as suspicious.

â€œI think things like that will actually happen, you will start to see things like memory misuse, tool misuse, or prompt injections,â€ he said.

â€œAll the vulnerabilities that large language models have been having for the last two years embedded on top of the agentic actions, I think, is going to become a lot more complicated for CISOs to secure.â€

Other risks Pasha identified include â€˜objective driftâ€™, in which agents gradually divert from their intended actions, and data vulnerabilities posed by

shadow AI

applications.

Palo Alto Networks found the average organization currently runs 66 generative AI applications and has released a feature in its

next-generation firewall

known as AI Access Security that allows administrators to identify and control user access to AI apps on a corporate network.

On a fundamental level, effective controls against these risks donâ€™t require brand new techn

[Content truncated...]

---

## âœ“ What Are Orchestrator Agents? AI Tools Working Smarter Together - YouTube

**URL:** https://www.youtube.com/watch?v=X3XJeTApVMM&

About

Press

Copyright

Contact us

Creator

Advertise

Developers

Terms

Privacy

Policy & Safety

How YouTube works

Test new features

Â© 2026 Google LLC

---

## âœ— https://www.gartner.com/en/newsroom/press-releases/2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027

**URL:** https://www.gartner.com/en/newsroom/press-releases/2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027

Error scraping: 403 Client Error: Forbidden for url: https://www.gartner.com/en/newsroom/press-releases/2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027

---

## âœ“ Why 'agent' is misleading in AI. Workflow + Agent = ROI | Wade Foster posted on the topic | LinkedIn

**URL:** https://www.linkedin.com/posts/wadefoster_stop-calling-everything-an-agent-folks-activity-7386101810576551937-Jc6Y

Wade Foster

3mo

Report this post

â€œStop calling everything an agentâ€

Folks are slapping 'agent' on anything that touches AI. Itâ€™s confusing.

I jumped on

Peter Yang

â€™s podcast to unpack why thatâ€™s misguided, and why the middle ground (agentic workflows) is where real ROI lives.

Workflows = determinism and reliability

Agents = judgment and flexibility

Stitch them together and you get the safest, most powerful form of AI orchestration. Give your agent just enough tools and context to do one job exceptionally well, and orchestrate the rest with workflows.

Two examples of this Iâ€™m using personally:

ğ—˜ğ˜…ğ—²ğ—°ğ—–ğ—¼ğ—»ğ—»ğ—²ğ—°ğ˜ (Workflow / Determinism)

ğŸ‘‰ A teammate submits an Interfaces form to request exec engagement, the AI drafts an on-brand message, posts to Slack, and tracks it in Tables. This one runs hundreds of times a month. Zero chaos, total clarity

ğ—œğ—»ğ—¯ğ—¼ğ˜… ğ— ğ—®ğ—»ğ—®ğ—´ğ—²ğ—ºğ—²ğ—»ğ˜ (Agent / Inference)

ğŸ‘‰ When a new email arrives, the agent reads it, checks HubSpot, uses reasoning to categorize it, and sorts it in Slack. It flags customers, intelligently routes the right things to my EA

Cortney

, and clears all of the noise. It reasons like a human assistant, saving us hours each week with full transparency logs

Cortney

â€™s Inbox Management agent is actually available as a template, you can steal it here:

https://lnkd.in/gpY9hQ2a

Full episode coming soon. Thanks for having me,

Peter

.

â€¦more

2,139

115 Comments

Like

Comment

Share

Copy

LinkedIn

Facebook

X

Ryan Duguid

3mo

Report this comment

Amenâ€¦ though if it raises awareness of the potential for good old fashioned deterministic workflows, who are we to argue ğŸ™‚

Like

Reply

6Â Reactions

7Â Reactions

Robert Baran

3mo

Report this comment

Why make it more confusing by differentiating the naming? What do end users care? Does it solve their problem then great call it whatever you want

Like

Reply

1Â Reaction

Diana Kirby

3mo

Report this comment

I agree "stop calling everything an agent," but I do think that's what's going to stick.

If we need to differentiate it, *we* need to explain it in a different way.

Workflow, Ai Workflow, Agentic Workflow, and Agent are way too similar for the general public to differentiate, so they won't.

Once society decides what something is (i.e. "vibe coding" is still the stupid name of choice) that's what we call it, and it's much harder to change society. Humans also like to consolidate things- so the list above is most easily summarized by "Agent:" the shortest, simplest descriptor.

Society does *not* care what the difference is between an "Agentic Workflow" and an "agent.They're just going to choose the simplest option for them which is "Agent."

I care and experts care, but laypeople or experts calling it what a layperson is most likely to click on, isn't going to go through the trouble to educate folks on things that to the general public "it's all Ai to them."

Like

Reply

1Â Reaction

2Â Reactions

Daniel Marcus

4d

Report this comment

"total clarity" and "reasons like a human" have no place in a serious discussion about AI. My "total clarity" and human reasoning flag this post as corporate bovine excretory matter. Though, to be fair, AI can probably figure that comment out because it will still match basic pattern recognition.

To be clear, AI, either that runs on demand or as an agent (service), IS useful. But by nature it's not deterministic, and it doesn't have intelligence or "human" reasoning. AI can't be 100% trusted for either given example, and giving any other impression is either genuinely naive or pure marketing.

Like

Reply

1Â Reaction

James Pember

3mo

Report this comment

i do agree that the biggest enterprise opportunity right now is agentic (or ai-augmented) workflows. that said, i do think agents (i.e. "an llm that runs tools in a loop to achieve a goal") are starting to work, particularly for coding. i hope we'll see another breakthrough use case for knowledge work soon.

(credit to

Simon Willison

for the agents definition).

https://jamespember.substack.com/p/everyones-using-llms-in-production

Like

Reply

1Â Reaction

2Â Reactions

Evan Kirstel

3mo

Report this comment

AI synergy at its best! ğŸ™ŒğŸ‘ğŸš€

Join us on

TECH IMPACTâ„¢ - National Television Series

or our podcast (

https://linktr.ee/evankirstel

) to explore whats next!

Like

Reply

2Â Reactions

3Â Reactions

Alexander Kazanski

1mo

Report this comment

This distinction between workflows and agents is so crucial. Too often, people conflate flexibility with reliability. I like the concept of giving an agent just enough context and tools to excel at a single task while orchestrating the rest with deterministic workflowsâ€”itâ€™s a practical way to balance trust and scalability in AI systems.

Iâ€™d love to see more examples of hybrid setups where multiple agentic workflows collaborate without creating chaos.

Like

Reply

1Â Reaction

Nick Kramer

3mo

Report this comment

That's right. â€œAgentâ€ has become the new buzzword, and itâ€™s blurri

[Content truncated...]

---

## âœ“ LangGraph

**URL:** https://www.langchain.com/langgraph

Trusted by companies shaping the future of agents

See LangGraph use cases in production

Controllable cognitive architecture for any task

LangGraph's flexible framework supports diverse control flows â€“ single agent, multi-agent, hierarchical, sequential â€“ and robustly handles realistic, complex scenarios.

Ensure reliability with easy-to-add moderation and quality loops that prevent agents from veering off course.

Use LangGraph Platform to templatize your cognitive architecture so that tools, prompts, and models are easily configurable with LangGraph Platform Assistants.

See the docs

Thousands of companies build AI apps better with LangChain products.

Read our select customer stories.

Designed for human-agent collaboration

With built-in statefulness, LangGraph agents seamlessly collaborate with humans by writing drafts for review and awaiting approval before acting. Easily inspect the agentâ€™s actions and "time-travel" to roll back and take a different action to correct course.

Read a conceptual guide

How does LangGraph help?

Guide, moderate, and control your agent with human-in-the-loop

Prevent agents from veering off course with easy-to-add moderation and quality controls. Add human-in-the-loop checks to steer and approve agent actions.

Learn how to add human-in-the-loop

Build expressive, customizable agent workflows

LangGraphâ€™s low-level primitives provide the flexibility needed to create fully customizable agents. Design diverse control flows â€” single, multi-agent, hierarchical â€” all using one framework.

See different agent architectures

Persist context for long-term interactions

LangGraphâ€™s built-in memory stores conversation histories and maintains context over time, enabling rich, personalized interactions across sessions.

Learn about agent memory

First-class streaming for better UX design

Bridge user expectations and agent capabilities with native token-by-token streaming, showing agent reasoning and actions in real time.

See how to use streaming

First class streaming support for better UX design

Bridge user expectations and agent capabilities with native token-by-token streaming and streaming of intermediate steps, helpful for showing agent reasoning and actions back to the user as they happen. Use LangGraph Platform's API to deliver dynamic and interactive user experiences.

Learn more

Introduction to LangGraph

Learn the basics of LangGraph in this LangChain Academy Course. You'll learn how to build agents that automate real-world tasks with LangGraph orchestration.

Enroll for free

Deploy agents at scale, monitor carefully, iterate boldly

Design agent-driven user experiences with LangGraph Platform's APIs. Quickly deploy and scale your application with infrastructure built for agents. Choose from multiple deployment options.

Fault-tolerant scalability

Handle large workloads gracefully with horizontally-scaling servers, task queues, and built-in persistence. Enhance resilience with intelligent caching and automated retries.

Dynamic APIs for designing agent experience

Craft personalized user experiences with APIs featuring long-term memory to recall information across conversation sessions. Track, update, and rewind your app's state for easy human steering and interaction. Kick off long-running background jobs for research-style or multi-step work.

Integrated developer experience

Simplify prototyping, debugging, and sharing of agents in our visual LangGraph Studio. Deploy your application with 1-click deploy with our SaaS offering or within your own VPC. Then, monitor app performance with LangSmith.

Developers trust LangGraph to build reliable agents

LangGraph helps teams of all sizes, across all industries, build reliable agents ready for production.

Hear how industry leaders use LangGraph

â€œLangChain is streets ahead with what they've put forward with LangGraph. LangGraph sets the foundation for how we can build and scale AI workloads â€” from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.â€

Garrett Spong

Principal SWE

â€œLangGraph has been instrumental for our AI development. Its robust framework for building stateful, multi-actor applications with LLMs has transformed how we evaluate and optimize the performance of our AI guest-facing solutions. LangGraph enables granular control over the agent's thought process, which has empowered us to make data-driven and deliberate decisions to meet the diverse needs of our guests.â€

Andres Torres

Sr. Solutions Architect

â€œAs Ally advances its exploration of Generative AI, our tech labs is excited by LangGraph, the new library from LangChain, which is central to our experiments with multi-actor agentic workflows. We are committed to deepening our 

[Content truncated...]

---

## âœ“ Swarnendu De - SaaS and AI Tech Leader

**URL:** https://www.swarnendu.de/

Hello Friends ğŸ‘‹

Iâ€™m Swarnendu De

Iâ€™m a SaaS and AI tech leader, author of advanced tech books, and co-founder of Innofied and AllRide Apps.

Work With Me

Subscribe to

Swarnenduâ€™s Newsletter

Join a growing community of more than 200,000+ founders, CTOs and product leaders.

200+ Reviews

Each week, I share actionable insights, frameworks, ideas about building SaaS and AI products, driving growth, and accelerating your career.

Subscribe

By submitting this form, youâ€™ll be signed up to my free newsletter. You can opt-out at any time

Worked With The Most Recognised Brands

About Me

Building Winning Products

A tech builder, framework nerd, and someone who genuinely enjoys turning messy product ideas into working, scalable software.

I help SaaS founders and startup/enterprise product teams go from â€œwe have an ideaâ€ to â€œthis thing actually works and scales.â€ With my team at Innofied and AllRide Apps, we build AI-powered platforms, automation systems, and digital products that donâ€™t fall apart when users show up.

Iâ€™ve built a few frameworks over the years (because templates are great, but predictable chaos is better) â€“ the

SaaS Product Success Strategyâ„¢

and

TechBlueprint

Framework

â„¢

â€“ which we use to cut through the noise and ship faster with fewer regrets.

When Iâ€™m not buried in client projects, I teach through my

courses

, post breakdowns and share experiences on my

YouTube channel

, and run

strategy sessions

where we simplify, untangle, and build with intent.

Read full story.

600+

Products Delivered

29

Countries Served

10k+

Online Students

8

Award Winner

How Can I Help You?

Build Your SaaS Product

I help you design and build scalable SaaS systems with clean architecture, modular structure, and processes that support fast iteration and long-term growth.

AI Strategy & Development

I help you identify the right use cases for AI, then architect and implement intelligent workflows that drive automation, efficiency, and product differentiation.

Technical Architecture & Product Planning

I bring clarity from day zero â€“ defining product scope, flows, and system design so you can move from idea to launch with speed and technical confidence.

Be Your Technical Advisor

I work closely with founders and teams as a strategic technical partner â€“ guiding architecture, product decisions, and execution with a system-first mindset.

Work With Me

My Upcoming Book

Orchestrate â€“ Mastering Multi-Agent AI in Business Automation

Orchestrate is a practical playbook on building agentic AI systems and business automation that works, for startups and enterprises alike. Itâ€™s built on real frameworks I use to design scalable, AI-powered software.

Learn More

Videos on Strategies & Frameworks

AI Chatbot Architecture: MVP to Enterprise

September 25, 2025

SaaS Microservice Architechture Patterns Explained (with Real world examples)

September 11, 2025

Strategies To Cut Your SaaS Development Cost

September 4, 2025

How Harvey AI Became $5B Legal Tech Giant: Enterprise AI Use Case

August 30, 2025

How Klarna used AI to replace 700 Agents

August 26, 2025

How To Hire The Perfect SaaS Development Team â€“ Complete Guide

August 25, 2025

All Videos

Subscribe to

Swarnenduâ€™s Newsletter

Each week, I share actionable insights, frameworks, ideas about building SaaS and AI products, driving growth, and accelerating your career.

200+ Reviews

Join a growing community of more than 200k+ founders, CTOs and product leaders.

Subscribe

By submitting this form, youâ€™ll be signed up to my free newsletter. You can opt out at any time ğŸ˜‰

---

## âœ“ LangGraph â€“ Orchestration at Enterprise Scale

**URL:** https://www.linkedin.com/pulse/langgraph-orchestration-enterprise-scale-sidd-tumkur-yscie

Lang Graph

Why Orchestration Matters

So far in this series, weâ€™ve covered:

LangChain

â€“ the framework for reusable building blocks.

LangFlow

â€“ democratizing prototyping.

LangSmith

â€“ adding trust and observability.

But thereâ€™s a problem: real enterprise processes arenâ€™t

linear chains

. They branch, loop, escalate, and combine multiple systems.

In

claims processing

, some cases auto-approve, some escalate to human adjusters, some get flagged for fraud.

In

compliance review

, some answers are direct, some require multiple document lookups, others need legal oversight.

In

customer support

, queries may start in an FAQ but escalate to billing or IT depending on intent.

Linear chains canâ€™t handle this complexity.

LangGraph

can.

LangGraph in the AI Operating System

LangGraph is the

orchestration layer

. It transforms simple chains into

stateful, auditable workflows

where:

Nodes represent steps (retriever, classifier, agent).

Edges define branching logic (confidence thresholds, conditions).

State carries context across the graph.

This makes LangGraph ideal for

multi-agent and multi-path workflows

â€” the kind enterprises actually run.

Hands-On Example â€“ Claims Triage Workflow

Imagine an insurance claim enters the system. With LangGraph, you can design a flow like this:

Classifier Node

â†’ route to â€œAuto,â€ â€œHome,â€ or â€œOther.â€

Policy Retriever Node

â†’ fetch relevant policy sections.

Risk Scorer Node

â†’ output fraud likelihood.

Confidence Gate

â†’

If score â‰¥ 0.9 â†’ auto-approve.

If 0.6â€“0.9 â†’ escalate to human adjuster (HITL).

If < 0.6 â†’ route to fraud investigation.

LangSmith traces every branch taken.

Compliance sees not just the outcome but the

decision path

.

Why LangGraph is Critical for Governance

LangGraph isnâ€™t just about complexity â€” itâ€™s about

safety and explainability

.

Retries

â†’ if an API fails, the graph retries or routes to fallback.

Refusal nodes

â†’ enforce â€œNot found in knowledge baseâ€ when evidence is missing.

Escalation

â†’ confidence gates ensure high-risk cases always reach humans.

Auditability

â†’ every path through the graph is logged.

This is orchestration not just for scale â€” but for

trust

.

Enterprise Use Cases

Banking

â†’ routing regulator queries to the right handbook, escalating low-confidence answers.

Healthcare

â†’ triage flows that detect severe symptoms and escalate to doctors automatically.

Retail

â†’ omnichannel support: FAQ retriever â†’ API lookup â†’ escalation to live agent.

Insurance

â†’ fraud detection workflows combining multiple scoring agents in parallel.

Leadership Lessons

For CIOs, CDOs, and CAIOs, the message is clear:

AI isnâ€™t about single assistants â€” itâ€™s about

workflow orchestration

.

LangGraph is the

process scheduler

of the AI Operating System.

If you want explainability at scale, every decision path must be visible, logged, and auditable.

LangGraph turns AI from fragile scripts into

enterprise workflows

. It ensures automation is safe, scalable, and always subject to human oversight when needed.

Thatâ€™s why in The AI Operating System I call LangGraph the orchestration layer: the engine that makes AI production-ready at scale.

ğŸ“˜

This article is adapted from my upcoming book:

The AI Operating System â€“ Building Safe, Scalable, and Explainable AI with the Lang Suite

, by Sidd Tumkur.

ğŸ‘‰ In the next article:

Governance by Design â€“ Why Refusal Rules, HITL, and Audit Trails Must Be Non-Negotiable.

---

## âœ— https://qr.ae/pCSqNV

**URL:** https://qr.ae/pCSqNV

Error scraping: 403 Client Error: Forbidden for url: https://www.quora.com/unanswered/Which-is-the-best-orchestration-tool-for-software-development?ch=10&oid=10048107&share=7fd74a90&srid=uxA5km&target_type=question

---

## âœ“ Context Engineering â€“ How I Fixed AI Coding Agents Forgetting My Codebase - Indie Hackers

**URL:** https://www.indiehackers.com/post/context-engineering-how-i-fixed-ai-coding-agents-forgetting-my-codebase-3HTRkqcJEyMKBzT6B3od

5

Likes

0

Bookmarks

2

Comments

When I first started using AI coding agents, I expected them to feel like supercharged teammates. Instead, I kept running into the same wall:

context loss

.

No matter which model I used, the pattern was the same:

Too little context â†’ they hallucinated and wrote nonsense.

Dump the whole repo â†’ they got lost and inconsistent.

Across prompts â†’ they forgot my architecture and conventions entirely.

It was frustrating, because I wasnâ€™t asking the AI to do something impossible. I just wanted it to act like a junior developer who understood the project, remembered the patterns, and could follow through on a feature.

This problem is what pushed me into

Context Engineering

â€” the practice of deliberately shaping and delivering the right context to coding agents.

The issue I had with coding agents

Let me give you an example.

Iâ€™d ask the agent to add a new feature â€” say, authentication in a Next.js app. The problem was, it had no memory of how the database was structured, how routes were organized, or which naming conventions I used.

Sometimes it invented new files instead of editing the right ones.

Sometimes it ignored the folder structure and just dumped code in random places.

Other times, it mixed naming styles so the code looked like three different people had worked on it.

The more the project grew, the worse this became. Small hallucinations turned into bigger architectural messes.

The solution I tried manually

At first, I hacked together a manual process. Before asking the agent to code, I prepared:

A

PRD (Product Requirements Doc)

written in plain English.

A

current vs target state diagram

of the architecture.

A

step-by-step task list

so the agent worked incrementally.

File references

so it knew exactly where to make changes.

This worked surprisingly well. With this structured context, the agent produced code that actually fit into my repo. I even managed to ship real features to production this way.

But it came at a cost: endless copy-pasting, repeating myself, and writing mini-specs by hand. For every feature, I was spending more time preparing context than writing code.

Thatâ€™s when it clicked: I didnâ€™t just have a prompting problem, I had a

context engineering problem

.

How Context Engineer MCP was built

To solve it once and for all, I built

Context Engineer MCP

.

Itâ€™s an MCP (Model Context Protocol) server that plugs into IDE-native agents like Cursor or Claude Code. Instead of me manually prepping context, it automates the process:

Repo scan:

Understands your architecture and tech stack.

PRD + tech blueprint:

Generates a spec and target plan before coding starts.

Actionable tasks:

Breaks down work step by step, like a senior dev would.

File awareness:

Ensures edits happen in the right places, no duplicates.

Privacy by design:

Runs locally, so your code never leaves your machine.

With this setup, the agent always starts with the right context. Itâ€™s like having a project manager and architect embedded in your workflow.

Final thoughts

Context Engineering isnâ€™t about bigger prompts. Itâ€™s about smarter context.

AI coding agents arenâ€™t failing because theyâ€™re weak models. Theyâ€™re failing because we feed them either too little or too much. With the right context â€” structured, precise, and grounded in your repo â€” they can become actual teammates instead of disposable chatbots.

Thatâ€™s the mission behind

Context Engineer MCP

, and why I think

Context Engineering

will be a key practice for anyone coding with AI in the future.

Alex

posted to

Context Engineer MCP

5

0

Share

Say something nice to the_context_engineerâ€¦

Post Comment

1

100%

I am glad this resonates with other people as well!

Alex

Â·

5 months ago

Â·

Reply

Â·

Edit

1

This hit home. Context loss is the single biggest reason most people walk away thinking â€œAI coding agents donâ€™t work.â€ You can throw the best model at the problem, but if itâ€™s oscillating between amnesia and overexposure, you end up with the kind of repo spaghetti you described. Random files, inconsistent conventions, three styles of naming in the same PR. Iâ€™ve been there.

When I started coding with Claude, I ran into the same wall and ended up building my own orchestration layer just to manage memory and context delivery. The trick wasnâ€™t to make prompts longer, it was to structure the conversation like you would with a junior dev: define the requirements, diagram the target state, break it into atomic tasks, then hand over just enough context at the right moment. That step-by-step scaffolding is what turns â€œhallucinatory internâ€ into â€œteammate who actually ships.â€

What youâ€™ve done with Context Engineer MCP is basically formalizing that orchestration into a reusable pattern, which is exactly whatâ€™s needed. Repo scanning, PRD generation, task breakdown, file awareness. All automated instead of endless copy-pasting is a huge win. Itâ€™s the same insight I landed on: models arenâ€™t the limi

[Content truncated...]

---

## âœ“ The Complete Guide to AI Multi-Agent Orchestration with Manus AI

**URL:** https://natesnewsletter.substack.com/p/the-complete-guide-to-ai-multi-agent

Playback speed

Ã—

Share post

Share post at current time

Share from 0:00

0:00

/

0:00

Playback speed

Ã—

Share post

0:00

/

0:00

Preview

Audio playback is not supported on your browser. Please upgrade.

40

8

2

The Complete Guide to AI Multi-Agent Orchestration with Manus AI

A Quick Readable Summary Plus 178 Pages of Manus Use Cases, an Agentic AI Framework, Live Dashboards, and Practical Prompts

Nate

Sep 02, 2025

âˆ™ Paid

40

8

2

Share

Everyone's building individual AI agents. Almost nobody's figured out how to make them work together.

And itâ€™s hard to get your agents to work as a team when we canâ€™t agree on what we even mean by AI agents! The truth is nobody has figured out how to talk coherently about how many different types and classes of AI agents are out thereâ€”weâ€™re all swimming in an ocean of AI agent hype, but practical guides are thin on the ground.

I've been

writing about AI agents

for months now. Yesterday I shared my deep dive into

n8n

â€”showing you how to build workflow agents, connect APIs, handle errors, all the practical stuff. That guide ran 20,000+ words because I wanted to document everything: what actually works, what breaks, what's worth your time. That whole n8n guide was focused on the problem of building really good individual agents.

This guide goes to the next level.

Because even when you get good at building individual agents, orchestrating multiple agents to work together is a different beast entirely. You end up manually copying outputs from one system to another, trying to coordinate work that should be coordinated automatically.

That's where Manus comes in. And I need to explain what Manus actually is, because I donâ€™t think itâ€™s been properly classified.

Manus is not an agent. It is not a collection of agents (as often reported). No. Manus is an autonomous AI agent platform. Not a chatbot, not a workflow builderâ€”it's a system that can plan and execute complete projects with minimal supervision. You give it a high-level goal like "analyze my competitors and create a report" and it breaks that down into steps, executes them using specialized sub-agents, and delivers finished work.

The difference matters. With ChatGPT, you're having a conversation. With n8n, you're building the exact workflow. With Manus, you're describing an outcome and letting it figure out the path. It's not better or worseâ€”it's a different layer of the stack.

And Iâ€™ve chosen Manus because in many ways it is the easiest path into multi-agent orchestrationâ€”and all the productivity unlocks that you get with multiple agents working the same problem.

So why now? Manus launched in March after all.

Well the truth is Manus wasnâ€™t mature enough for a guide like this in March.

Thatâ€™s why I'm writing about this now: Manus is finally through the teething problems associated with launch in the spring. I think itâ€™s worth paying attention to now as the product has matured, and I want you to have the resources to use it properly.

With that in mind, I've assembled what's probably the most comprehensive collection of Manus resources available anywhere. And thatâ€™s not all! I think part of the issue with Manus is that understanding and classifying agents is hard, so Iâ€™ve assembled a framework for understanding autonomous agentsâ€”not just Manus, but the whole categoryâ€”needs to be spelled out clearly. We need shared language for talking about what these systems can and can't do.

Here's what's in the box with this article:

The 178-page Manus AI Handbook

- This is the real technical documentation. How the three-layer architecture works (planning, execution, validation). What it can actually do (web browsing, code generation, data analysis, API calls, deployment). What it struggles with (perfect accuracy, deep expertise, real-time tasks). Actual case studies with numbers. If you wanted to understand Manus deeply, this is what you'd need.

My Substack article

- I've walked through specific Manus examples with my testing notes. Where it shines (complex multi-step projects), where it falls apart (tasks needing specialized knowledge), and when you should use it versus other approaches.

Two live dashboards Manus built

- Not mockups. Manus actually built these itself:

A SaaS metrics dashboard with synthetic data - Manus worked hard on this one, generating realistic sample data and building the full visualization layer

An AI agents explorer showing the MACE (Multi-Agent Collaboration Engine) concept I introduce in the Substack. These demonstrate that Manus builds simple, fully functional applications, not just text outputs. You can click around, interact with them, see how they work.

Manus's guide to itself

- I asked Manus to document its own capabilities. It's surprisingly honest about its limitations. Worth reading to understand how these systems see themselves.

Why naming the framework matters (and itâ€™s not boring):

We're terrible at talking about AI agents. People say "AI agent" and might mean

[Content truncated...]

---

## âœ— https://www.producthunt.com/p/producthunt/the-best-ai-workflow-automation-tools

**URL:** https://www.producthunt.com/p/producthunt/the-best-ai-workflow-automation-tools

Error scraping: 403 Client Error: Forbidden for url: https://www.producthunt.com/p/producthunt/the-best-ai-workflow-automation-tools

---

## âœ— https://medium.com/%40timarkanta.sharma/llm-orchestration-from-toy-prompts-to-real-systems-7577b33fbe70

**URL:** https://medium.com/%40timarkanta.sharma/llm-orchestration-from-toy-prompts-to-real-systems-7577b33fbe70

Error scraping: 403 Client Error: Forbidden for url: https://medium.com/%40timarkanta.sharma/llm-orchestration-from-toy-prompts-to-real-systems-7577b33fbe70

---

## âœ“ AI Agent Development Cost: Key Factors & Practical Pricing Guide - Indie Hackers

**URL:** https://www.indiehackers.com/post/ai-agent-development-cost-key-factors-practical-pricing-guide-030c49650c

The AI agent development market has exploded, with businesses investing billions in intelligent automation solutions. Understanding AI agent development cost is crucial for organizations planning to implement these technologies. Businesses benefits from

adopting AI in mobile apps

. It helps organizations realize the strategic value of AI agent investments. From simple chatbots to complex multi-agent systems, pricing varies dramatically based on functionality, complexity, and implementation requirements.

Development Costs Based on the Types of AI Agents

Reactive (Simple Reflex) Agents

Reactive agents represent the most straightforward AI systems, responding directly to current inputs without memory or learning capabilities. These simple reflex agents cost between $15,000 to $40,000 to develop, making them ideal for basic customer service applications and simple automation tasks.

Model-Based Reflex Agents

Model-based agents incorporate internal state representations, allowing them to handle partially observable environments more effectively than reactive agents. Development costs range from $30,000 to $80,000, depending on the complexity of the model architecture and state management requirements.

Goal-Based Agents

Goal-based agents can plan and execute sequences of actions to achieve specific objectives. These intelligent systems cost between $50,000 to $150,000 to develop, reflecting the sophisticated planning algorithms and decision-making capabilities required.

Utility-Based Agents

Utility-based agents optimize decisions based on preference measures and utility functions, requiring advanced mathematical modeling. Development costs typically range from $80,000 to $200,000 for these sophisticated decision-making systems.

Learning Agents

Learning agents adapt and improve performance over time through experience and feedback. Development costs start at $100,000 and can exceed $300,000 for complex implementations with advanced machine learning capabilities.

Collaborative Agents

Collaborative agents work together in multi-agent environments, requiring sophisticated coordination mechanisms and communication protocols. These systems represent the highest cost category, often exceeding $250,000 for full implementation due to their complexity.

Modern Business-Centric AI Agent Types

Simple Chatbot

Basic AI chatbot cost varies significantly based on capabilities. Simple rule-based chatbots cost $10,000 to $30,000, while more sophisticated conversational AI systems can reach $50,000 to $100,000 depending on natural language processing requirements.

LLM-Powered Task Agent

LLM-powered agents leverage large language models for natural language processing and task execution. Development costs range from $75,000 to $250,000, depending on model integration complexity, customization requirements, and specific task automation needs.

Retrieval-Augmented Generation (RAG) Agent

RAG agents combine knowledge bases with

generative AI capabilities

, creating powerful information retrieval and generation systems. These sophisticated agents typically cost $100,000 to $300,000, reflecting the complexity of integrating retrieval and generation components effectively.

Multi-Agent System with Planning

Multi-agent systems coordinate multiple AI agents for complex problem-solving and planning tasks. Development costs often exceed $200,000 due to the sophisticated orchestration, communication protocols, and planning algorithms required for effective multi-agent coordination.

Feature Evaluation Across Pricing Tiers

Basic Tier ($25K â€“ $50K)

The basic AI agent pricing tier includes simple reactive or model-based agents with limited functionality. Features typically include:

Basic natural language processing capabilities

Rule-based decision making systems

Simple integration with existing systems

Basic customer service automation

Limited customization options

These solutions work well for straightforward customer service applications or basic process automation tasks.

Mid-Range Tier ($50K â€“ $150K)

Mid-range solutions offer goal-based or utility-based agents with enhanced capabilities. The AI agent pricing in this tier includes:

Advanced machine learning integration

Moderate customization and configuration options

Enhanced natural language understanding

Integration with multiple business systems

Workflow automation capabilities

Basic learning and adaptation features

Advanced Tier ($150K â€“ $400K+)

Premium solutions feature learning agents or collaborative multi-agent systems. Advanced AI agent pricing includes:

Sophisticated machine learning models and algorithms

Extensive customization and personalization capabilities

Real-time learning and continuous adaptation

Complex workflow automation and orchestration

Enterprise-grade security and compliance features

Multi-agent coordination and advanced planning

Key Factors That Influence AI Agent Development Cost for Custom Software

Development Approach


[Content truncated...]

---

## âœ“ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/LangChain/comments/1okh4x2/is_langgraph_the_best_framework_for_building_a/

Go to LangChain

r/LangChain

â€¢

Specific_Ad_3250

FranÃ§ais

à¤¹à¤¿à¤¨à¥à¤¦à¥€

Ğ ÑƒÑÑĞºĞ¸Ğ¹

PortuguÃªs (Brasil)

EspaÃ±ol (LatinoamÃ©rica)

à¹„à¸—à¸¢

Deutsch

Is LangGraph the best framework for building a persistent, multi-turn conversational AI?

Recently I came across a framework (yet to try it out) Parlant, in which they mentions "LangGraph is excellent for workflow automation where you need precise control over execution flow. Parlant is designed for free-form conversation where users don't follow scripts."

Read more

Share

---

## âœ“ Orchestrator Agents & MCP: How AI Agents Drive Automation - YouTube

**URL:** https://www.youtube.com/watch?v=Ons1Fv3IE4U&

About

Press

Copyright

Contact us

Creator

Advertise

Developers

Terms

Privacy

Policy & Safety

How YouTube works

Test new features

Â© 2026 Google LLC

---

## âœ“ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/LangChain/comments/1o19qln/how_do_you_work_with_state_with_langgraphs/

Go to LangChain

r/LangChain

â€¢

francescola

FranÃ§ais

Ğ ÑƒÑÑĞºĞ¸Ğ¹

Italiano

à¹„à¸—à¸¢

How do you work with state with LangGraph's createReactAgent?

I'm struggling to get the mental model for how to work with a ReAct agent.

When just building my own graph in langgraph it was relatively straightforward - you defined state, and then each node could do work and mutate that state.

With a ReAct agent it's quite a bit different:

Tool calls return data that gets placed into a ToolMessage for the LLM to access

The agent still has state which you can:

Read in a tool using getCurrentTaskInput

Read/write in the pre and postModelHooks

Maybe you can mutate state from within the tool but I have no clue how

My use case: I want my agent to create an event in a calendar, but request input from the user when something isn't known.

I have a request_human_input tool that takes an array of clarifications and uses interrupt. Before I pause, I want to add deterministic IDs to each clarification so I can match answers on resume. I see two options:

Add a postModelHook that detects when we are calling this tool and generates these IDs, puts them in the state object, and the tool reads them (awkward flow)

Make an additional tool that takes the array of clarifications and transforms it (adds the IDs) before I call the tool with the interrupt (extra LLM call for no real reason)

QUESTION 1:

With ReAct agents what's the role of extra state (outside of messages). Are you supposed to rely solely on the agent LLM to call tools with the specified input based on the message history, or is there a first class way to augment this using state?

QUESTION 2:

If you have a tool that calls an interrupt how do you store information that we want to be able to access when we resume the graph?

Read more

Share

---

## âœ“ Build AI Agents & SaaS Apps Visually : Powered by Simplita ai - Indie Hackers

**URL:** https://www.indiehackers.com/post/build-ai-agents-saas-apps-visually-powered-by-simplita-ai-0845634670

Most tools automate tasks. Simplita builds products.

Visual AI builder to design, automate & launch full SaaS apps and own your code.

Launching Nov 18!!!!

https://simplita.ai

Join waitlist...

---

## âœ“ Companies confess their agentic AI goals aren't really working out - and a lack of trust could be why | TechRadar

**URL:** https://www.techradar.com/pro/companies-confess-their-agentic-ai-goals-arent-really-working-out-and-a-lack-of-trust-could-be-why

(Image credit: Getty Images)

Share

Share by:

Copy link

Facebook

X

Whatsapp

Reddit

Pinterest

Flipboard

Threads

Email

Share this article

0

Join the conversation

Follow us

Add us as a preferred source on Google

Business risks, transparency, and compliance are the biggest hurdles for agentic AI deployment

Nearly half of organizations are running AI agents in silos

Allowing AI to adapt to workload variables is key

Three in four (73%) organizations admit there's a gap between their ambitions and reality when it comes to deploying agentic

AI tools

, and it's because they lack trust.

Just to drive that message home, a report from Camunda report reveals that despite 71% of organizations using AI agents, only 11% of use cases reached production last year.

Business risks (84%), transparency (80%) and regulatory/compliance concerns (66%) are the main hurdles â€“ but businesses are still going all-in on investments, leading to appallingly low ROI.

You may like

Most workplace AI projects are stuck at the concept stage - so what can be done to improve this?

Why agentic AI pilots stall â€“ and how to fix them

Iâ€™m an AI expert and hereâ€™s why agentic AI is moving from hype to ROIâ€¦ and how to deploy it safely at scale

Agentic AI isn't being used to its full potential

Four in five were found to be using AI agents as chatbots or assistants only, with nearly half (48%) admitting that their agentic systems work in silos, lacking full context.

Many AI agent applications also require human approval, preventing them from being as effective as the technology suggests.

"Right now, exercising caution with agentic AI means many organizations canâ€™t move beyond pilots or isolated use cases," Camunda Customer Success SVP Kurt Petersen wrote. "Once a foundation of trust is in place, agents can become powerful multipliers inside governed processes instead of siloed copilots or chatbots."

However, those who did use agentic AI's full capabilities saw strong results â€“ 95% saw business growth from automation, and nearly four in five (79%) plan to increase automation spend as a result. With tech stacks becoming far more distributed (76% agree), agentic AI could hold the key to tying multiple systems together.

Are you a pro? Subscribe to our newsletter

Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed!

Contact me with news and offers from other Future brands

Receive email from us on behalf of our trusted partners or sponsors

Camunda says the answer lies in agentic orchestration, which means the combination of deterministic orchestration (fixed rules and workflows) and dynamic orchestration (agentic AI being able to respond and adapt to variables).

Follow TechRadar on Google News

and

add us as a preferred source

to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!

And of course you can also

follow TechRadar on TikTok

for news, reviews, unboxings in video form, and get regular updates from us on

WhatsApp

too.

TOPICS

Craig Hale

With several yearsâ€™ experience freelancing in tech and automotive circles, Craigâ€™s specific interests lie in technology that is designed to better our lives, including AI and ML, productivity aids, and smart fitness. He is also passionate about cars and the decarbonisation of personal transportation. As an avid bargain-hunter, you can be sure that any deal Craig finds is top value!

Show More Comments

You must confirm your public display name before commenting

Please logout and then login again, you will then be prompted to enter your display name.

Logout

Read more

Most workplace AI projects are stuck at the concept stage - so what can be done to improve this?

Why agentic AI pilots stall â€“ and how to fix them

Iâ€™m an AI expert and hereâ€™s why agentic AI is moving from hype to ROIâ€¦ and how to deploy it safely at scale

From caution to confidence: Tackling AI obstacles with education

3 risks hindering enterprise-ready AI â€” and how low-code workflows help

From Black Box to White Box: why AI agents shouldnâ€™t be a mystery to enterprises

Latest in Pro

This dangerous North Korean malware has now split into three entities for maximum impact

Marquis confirms data breach, point finger of blame at SonicWall firewall

Over 175,000 publicly exposed Ollama AI servers discovered worldwide - so fix now

KYY X90E portable monitor review

Data sovereignty creates an illusion of security: the real battle is software integrity

The biggest DDoS attack ever has been detected - but fortunately you probably barely noticed it

Latest in News

Nvidia Shield TV updates will continue, and a new device may appear too

â€˜One month out, theyâ€™re still building Tomorrowlandâ€™: Disneyland Handcrafted reveals all

ICYMI: the week's 7 biggest tech news stories for January 31, 2026

Maingear Retro98 PC is a boxy beige tower, but packs cutting-edge hardware

Black Ops 7 Season 2 features se

[Content truncated...]

---

## âœ— https://www.reuters.com/business/over-40-agentic-ai-projects-will-be-scrapped-by-2027-gartner-says-2025-06-25/

**URL:** https://www.reuters.com/business/over-40-agentic-ai-projects-will-be-scrapped-by-2027-gartner-says-2025-06-25/

Error scraping: 401 Client Error: HTTP Forbidden for url: https://www.reuters.com/business/over-40-agentic-ai-projects-will-be-scrapped-by-2027-gartner-says-2025-06-25/

---

## âœ“ AI Agents: When Software Starts Running the Work

**URL:** https://studioalpha.substack.com/p/ai-agents-when-software-starts-running

AI Agents: When Software Starts Running the Work

Why the real shift in AI is not intelligence - but execution (Part 1)

Fabian Hediger

Jan 15, 2026

8

2

1

Share

In the previous blog about the

economics of AI

, we looked at AI from the outside: capital flows, infrastructure buildouts, falling token costs, and the uncomfortable conclusion that intelligence alone does not create economic value.

Before writing this piece, we had a long internal discussion about a simple question that turns out not to be simple at all:

What is an AI agent, really?

The term is everywhere. Slides, demos, product pages. And depending on who you ask, an agent is anything from a chatbot with tools to something that sounds suspiciously like the Terminator.

Loading...

* â€˜McKinsey challenges graduates to use AI chatbot in recruitment overhaulâ€™ -  FT, Jan 14, 2026

1

Of course, Prof. Andy came in with the science.

Definitions. Models. Maturity curves. Exciting, very.

So we ended up writing this piece â€“ not to add another opinion, but to

clarify what an agent actually is

, and what it is not. Stripped of hype. Grounded in how real systems behave.

Although is not as exciting as the title image might suggest.

No killer robots (are we sure?). No secret agents.

Mostly hard bread.

But if you care about how AI will actually change companies - not in demos, but in production - this distinction matters.

The rest of this post does exactly that. It starts by explaining why agents matter now, then pins down a precise definition, and finally shows why the real shift is not happening at the model layer, but one level up - where software starts to execute work.

Not glamorous.

But real.

Subscribe

1. Why AI Agents Matter Now

For a long time, progress in gen AI followed a familiar pattern.

Models got bigger.

Benchmarks improved.

Demos became smoother.

But if you look closely at how work is actually done inside companies, very little changed.

People still open tickets, copy data between systems, escalate edge cases by email, and coordinate across tools that were never designed to work together. The intelligence was there, but it lived between applications rather than inside them. Execution remained a human responsibility. (also compare our blog â€˜

Has MIT Opened Pandoraâ€™s Box on AI Being a Bubble?

â€™)

That gap is where AI agents enter - and the topic likely to dominate 2026.

Not as a new interface.

Not as a smarter chatbot.

But as a different execution model for software.

Agents matter now because large language models have crossed a practical threshold. They are not perfect, but they are reliable enough to reason across multiple steps, evaluate intermediate results, and decide what to do next. What they still lack is structure, control, and integration into real systems. Agents provide that missing layer.

Pic. Building an agent is a process of designing workflows and connecting pieces. Here an example of OpenAI (

source

)

OpenAI frames this shift explicitly by defining agents as systems that â€œindependently accomplish tasks on your behalf,â€ rather than systems that merely generate responses.

2

Microsoftâ€™s enterprise documentation makes a similar point, describing agents as long-running, goal-driven processes that operate across tools and workflows instead of inside a single UI.

3

This is not an AGI story.

It is an application-layer story.

And it is about what happens once models are â€œgood enough,â€ but software still doesnâ€™t actually do the work.

Pic. Simple overview

2. What Do We Mean by â€œAI Agentâ€

The word

agent

is currently overused to the point of losing precision.

Chatbots are called agents.

Copilots are called agents.

Scripted workflows are called agents.

Even classic automation tools rebrand themselves as â€œagentic.â€

So we need a definition that is not marketing-based, but rooted in what competent people have used for decades: an agent is defined by

behavior over time

- not by UI or marketing.

Pic.

Increasing levels of autonomy and control: from single LLM calls to full agents. (

Source

)

A canonical baseline comes from Russell & Norvig, who define an agent as something that perceives its environment and acts upon it to achieve goals. That framing predates GenAI, and itâ€™s still the cleanest starting point.

4

- I know, there are many other definitions.

A working definition (used throughout this series)

For this series, an â€œAI agentâ€ is a software system that:

pursues an explicit

goal

, not just a prompt

plans across

multiple steps

, not a single response

maintains

state

between steps

acts through

tools

(APIs, code, systems)

evaluates progress and decides whether to continue, adapt, stop, or escalate

This maps well to modern surveys of LLM-based agents that formalize agents as systems composed of objectives, memory, perception, action, and feedback loops rather than simple inputâ€“output functions.

5

Pic. Wang et al. â€”

LLM-based Autonomous Agents: A Surve

(

source

)



[Content truncated...]

---

## âœ“ Reddit - The heart of the internet

**URL:** https://www.reddit.com/r/LangChain/comments/1onoufx/building_a_langchainlanggraph_multiagent/

Go to LangChain

r/LangChain

â€¢

Thick-Ad3346

à¤¹à¤¿à¤¨à¥à¤¦à¥€

ÄŒeÅ¡tina

Italiano

Building a LangChain/LangGraph multi-agent orchestrator: how to handle transitions between agents in practice?

Hey everyone,

Iâ€™m experimenting with

LangGraph

and to build a

multi-agent system

that runs locally with

LangSmith tracing

.

Iâ€™m trying to figure out the

best practical way to manage transitions

between agents (or graph nodes), especially between an orchestrator and domain-specific agents.

Example use case

Imagine a

travel assistant

where:

The

user

says:

â€œI want a vacation in Greece under $2000, with good beaches and local food.â€

The

Orchestrator Agent

receives the message, filters/validates input, then calls the

Intent Agent

to classify what the user wants (e.g.,

intent = plan_trip

, extract location + budget).

Once intent is confirmed, the orchestrator routes to the

DestinationSearch Agent

, which fetches relevant trips from a local dataset or API.

Later, the

Booking Agent

handles the actual reservation, and a

Document Agent

verifies uploaded passport scans (async task).

The

user never talks directly to sub-agents

; only through the orchestrator.

What Iâ€™m trying to decide

Iâ€™m torn between these three patterns:

Supervisor + tool-calling pattern

Orchestrator is the only user-facing agent.

Other agents (Intent, Search, Booking, Docs) are â€œtoolsâ€ the orchestrator calls.

Centralized, structured workflow.

Handoff pattern

Agents can transfer control (handoff) to another agent.

The user continues chatting directly with the new active agent.

Decentralized but flexible.

Hybrid

Use supervisor routing for most tasks.

Allow handoffs when deep domain interaction is needed (e.g., user talks directly with the Booking Agent).

ğŸ§  What Iâ€™d love input on

How are you handling

transitions

between orchestrator â†’ intent â†’ specialized agents in

LangGraph

?

Should each agent be a

LangGraph node

, or a

LangChain tool

used inside a single graph node?

Any

best practices

for preserving conversation context and partial state between these transitions?

How do you handle

async tasks

(like doc verification or background scoring) while keeping the orchestrator responsive?

ğŸ§° Technical setup

LangGraph

LangChain

Local async execution

Tracing via LangSmith (local project)

All data kept in JSON or in-memory structures

Would really appreciate any architecture examples, open-source repos, or best practices on

agent transitions and orchestration design

in LangGraph. ğŸ™

Read more

Share

---

## âœ“ The Principles of Production AI - Inngest Blog

**URL:** https://www.inngest.com/blog/principles-of-production-ai

One main observation can be made as we approach the end of 2024: AI Engineering is maturing, looking for

a safer, more accurate, and reliable way to put RAGs and Agents into user's hands

.

Prompting iterations now rely on evaluations, or â€œEvals,â€ a technique inspired by classical Software Engineering's unit testing. AI Engineering also merges with software engineering architecture to support the orchestration of the

increasing need for more tools and the use of mixture-of-models in agentic workflows

.

This article covers the three pillars used in AI Engineering to fulfill its mission of providing users with a safe and reliable AI experience at scale:

LLM Evaluation

,

Guardrails

, and

better orchestration

.

LLM Evaluation: from unit testing to monitoring

What is LLM Evaluation?

LLM Evaluations assess the quality and relevance of responses that an AI model produces from given prompts. While partially inspired by unit testing, LLM evaluation does not just occur during the development and prototyping phases. It's now a best practice to continuously evaluate quality and relevance continuously, similar to A/B testing:

Using LLM Evaluation during development

consists of

benchmarking

the quality and relevance of your prompts.

When used in production

, LLM Evaluation (also called â€œOnline evalsâ€) helps

monitor the evolution

of your AI application quality over time and identify potential regression problems.

How to perform LLM Evaluation?

An LLM Evaluation is composed of four components:

An input (

the same as the one provided to the LLM model

)

An expected output

A Scorer or Evaluation Methods

An LLM model to call

The most crucial component of LLM evaluation is

the scorer or Evaluation Method

.

While regular Software Engineering Unit tests rely on matches (â€œis equalâ€, â€œmatchesâ€, â€œcontainsâ€), the unpredictable nature of LLM requires us to evaluate their responses with more flexibility.

For this reason, evaluation methods rely on statistical evaluation, such as the Levenshtein distance or using another

LLM as a judge

.

When moving to production, a good practice is to forward the logs of LLM operations and end-user feedback to an LLM observability tool.

The logs and user feedback are then sampled and evaluated against LLM as a judge Evaluation Method, and the results are plotted in time to highlight the over-time performance.

Takeaways

LLM Evaluation is now a crucial part of AI Engineering, serving as a Quality Assurance step in:

The prototyping phase

: helping in quickly iterating over prompts and model selection.

Releasing changes to production

: helping evaluate your AI workflows' performance over time and preventing regressions.

Let's now move to another pillar in moving AI safely to production: Guardrails.

Orchestration infrastructure: better reliability and cost efficiency

Many

papers

and

articles

were published earlier this year, showcasing the

outstanding performance of

combining multiple types of models and better leveraging tools.

New tools have been created to help orchestrate AI workflow's rising complexity, such as LangGraph and, recently,

OpenAI's swarm

. Still, these tools mainly focus on helping with quickly prototyping agentic workflows, leaving us to deal with the

main challenges of pushing AI workflows in production

:

Reliability and Scalability

: As AI workflows combine more external services (Evals, Guardrails), Tools (APIs), and models to achieve the best LLM performance, their complexity and exposure to external errors increase.

Cost Management

: Putting an AI application in production requires some Guardrails to protect the end users but doesn't protect the AI application from abuse, leading to unwanted LLM costs.

The multi-tenancy nature of AI applications

: Most AI applications rely on conversations or data from multiple users. This implies some architectural choice to prevent fairness issues (one user's usage shouldn't affect another) and data isolation to avoid data leaks.

As more companies release AI applications to production, many turn to AI workflow orchestration solutions to reliably operate their applications at scale.

AI Workflows as steps: reliability and caching included

One successful approach to operating AI workflows in production relies on

Durable Workflows

like Inngest.

Durable Workflows enable you to build AI workflows composed of retriable and linked steps (like chains) benefiting from three essential features:

Automatic retries

are crucial for reliably interacting with LLM models and tools at scale.

Embedded Caching

: preventing any duplicate costly LLM costs during retries

Concurrency, Throttling, and Rate limiting

are essential to scale user requests and protect your application from abuse.

A failure at the second step of an Inngest AI workflow doesn't trigger a rerun of the first LLM call.

Durable Workflows brings a modern approach to building long-running workflows composed of reliable steps, 

[Content truncated...]

---

